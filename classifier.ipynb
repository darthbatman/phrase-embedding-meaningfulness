{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southwest-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classifier implementation (model architecture, training, testing, etc.) derived from\n",
    "#     https://towardsdatascience.com/pytorch-tabular-binary-classification-a0368da5bb89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imported-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHRASE_LEN = 6\n",
    "VECTOR_SIZE = 200\n",
    "WINDOW_SIZE = 5\n",
    "NUM_LAYERS = 5\n",
    "\n",
    "MIN_FREQUENCY = 5\n",
    "\n",
    "SHOULD_EXTRACT_NOUN_PHRASES = False\n",
    "SHOULD_GENERATE_UNDERSCORED_CORPUS = False\n",
    "SHOULD_TRAIN_WORD2VEC_MODEL = False\n",
    "\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convertible-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 arxiv abstracts.\n"
     ]
    }
   ],
   "source": [
    "with open('data/arxiv_abstracts_10000.txt', 'r') as f:\n",
    "    arxiv_abstracts = f.read().split('\\n')[:-1]\n",
    "    arxiv_abstracts_raw = '\\n'.join(arxiv_abstracts)\n",
    "    f.close()\n",
    "print(f'Loaded {len(arxiv_abstracts)} arxiv abstracts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comic-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 negative samples.\n"
     ]
    }
   ],
   "source": [
    "negative_samples = pickle.load(open('data/negative_samples.pkl', 'rb'))\n",
    "print(f'Loaded {len(negative_samples)} negative samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mathematical-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 positive samples.\n"
     ]
    }
   ],
   "source": [
    "positive_samples = pickle.load(open('data/positive_samples.pkl', 'rb'))\n",
    "print(f'Loaded {len(positive_samples)} positive samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endangered-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrase(tree_str, label):\n",
    "    phrases = []\n",
    "    trees = Tree.fromstring(tree_str)\n",
    "    for tree in trees:\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == label:\n",
    "                t = subtree\n",
    "                t = ' '.join(t.leaves())\n",
    "                phrases.append(t)\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seven-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_EXTRACT_NOUN_PHRASES:\n",
    "    nlp = StanfordCoreNLP('data/stanford-corenlp-4.1.0')\n",
    "    noun_phrases = []\n",
    "    for i, abstract in enumerate(arxiv_abstracts):\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Extracting noun phrases from abstract {i + 1} of {len(arxiv_abstracts)}')\n",
    "            pickle.dump(noun_phrases, open('data/noun_phrases.pkl', 'wb'))\n",
    "        try:\n",
    "            tree_str = nlp.parse(abstract)\n",
    "            noun_phrases.extend(extract_phrase(tree_str, 'NP'))\n",
    "        except Exception:\n",
    "            pass\n",
    "    noun_phrases = [np for np in list(set(noun_phrases)) if len(np.split()) <= MAX_PHRASE_LEN]\n",
    "    pickle.dump(noun_phrases, open('data/noun_phrases.pkl', 'wb'))\n",
    "noun_phrases = pickle.load(open('data/noun_phrases.pkl', 'rb'))\n",
    "noun_phrases = [np for np in list(set(noun_phrases)) if len(np.split()) <= MAX_PHRASE_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fancy-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phrase_in_corpus(corpus, phrase):\n",
    "    s_idx = corpus.find(phrase)\n",
    "    e_idx = s_idx + len(phrase)\n",
    "    if s_idx != -1 and \\\n",
    "       (s_idx == 0 or corpus[s_idx - 1] in (string.punctuation + ' ')) and \\\n",
    "       (e_idx == len(corpus) or corpus[e_idx] in (string.punctuation + ' ')):\n",
    "        return (s_idx, e_idx)\n",
    "    return (-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "second-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    corpus = arxiv_abstracts_raw[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "golden-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    for i, positive_sample in enumerate(positive_samples):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Replacing positive_sample {i + 1} of {len(positive_samples)}')\n",
    "        found_indices = set()\n",
    "        while find_phrase_in_corpus(corpus, positive_sample) != (-1, -1) and find_phrase_in_corpus(corpus, positive_sample)[0] not in found_indices:\n",
    "            s_idx, e_idx = find_phrase_in_corpus(corpus, positive_sample)\n",
    "            found_indices.add(s_idx)\n",
    "            corpus = corpus[:s_idx] + positive_sample.replace(' ', '_') + corpus[e_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rough-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    for i, negative_sample in enumerate(negative_samples):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Replacing negative_sample {i + 1} of {len(negative_samples)}')\n",
    "        found_indices = set()\n",
    "        while find_phrase_in_corpus(corpus, negative_sample) != (-1, -1) and find_phrase_in_corpus(corpus, negative_sample)[0] not in found_indices:\n",
    "            s_idx, e_idx = find_phrase_in_corpus(corpus, negative_sample)\n",
    "            found_indices.add(s_idx)\n",
    "            corpus = corpus[:s_idx] + negative_sample.replace(' ', '_') + corpus[e_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "surprised-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    for i, noun_phrase in enumerate(noun_phrases):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Replacing noun_phrase {i + 1} of {len(noun_phrases)}')\n",
    "        found_indices = set()\n",
    "        while find_phrase_in_corpus(corpus, noun_phrase) != (-1, -1) and find_phrase_in_corpus(corpus, noun_phrase)[0] not in found_indices:\n",
    "            s_idx, e_idx = find_phrase_in_corpus(corpus, noun_phrase)\n",
    "            found_indices.add(s_idx)\n",
    "            corpus = corpus[:s_idx] + noun_phrase.replace(' ', '_') + corpus[e_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hispanic-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    pickle.dump(corpus, open('data/underscored_corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mineral-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "underscored_corpus = pickle.load(open('data/underscored_corpus.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "worldwide-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_TRAIN_WORD2VEC_MODEL:\n",
    "    underscored_corpus_data = []\n",
    "    for i in sent_tokenize(underscored_corpus):\n",
    "        temp = []\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j.lower())\n",
    "        underscored_corpus_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boolean-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_TRAIN_WORD2VEC_MODEL:\n",
    "    word2vec_model = Word2Vec(underscored_corpus_data, min_count=1, window=WINDOW_SIZE, size=VECTOR_SIZE)\n",
    "    word2vec_model.save(f'data/word2vec_model_vs_{VECTOR_SIZE}_ws_{WINDOW_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baking-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(f'data/word2vec_model_vs_{VECTOR_SIZE}_ws_{WINDOW_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "quantitative-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in list(word2vec_model.wv.vocab.keys())]\n",
    "embeddings = {token: word2vec_model.wv[token] for token in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "diagnostic-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = [ps for ps in positive_samples if ps.replace(' ', '_') in embeddings and word2vec_model.wv.vocab[ps.replace(' ', '_')].count >= MIN_FREQUENCY]\n",
    "negative_samples = [ns for ns in negative_samples if ns.replace(' ', '_') in embeddings and word2vec_model.wv.vocab[ns.replace(' ', '_')].count >= MIN_FREQUENCY]\n",
    "noun_phrases = [np for np in noun_phrases if np.replace(' ', '_') in embeddings and word2vec_model.wv.vocab[np.replace(' ', '_')].count >= MIN_FREQUENCY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beautiful-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for phrase in positive_samples:\n",
    "    X.append(embeddings[phrase.replace(' ', '_')])\n",
    "    y.append(1)\n",
    "for phrase in negative_samples:\n",
    "    X.append(embeddings[phrase.replace(' ', '_')])\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "brown-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X, y))\n",
    "random.shuffle(c)\n",
    "X, y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "utility-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complimentary-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(VECTOR_SIZE, 128)\n",
    "        \n",
    "        self.layers = []\n",
    "        for _ in range(NUM_LAYERS - 1):\n",
    "            self.layers.append(nn.Linear(128, 128))\n",
    "        \n",
    "        self.layer_out = nn.Linear(128, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = self.relu(layer(x))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "small-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifier(\n",
       "  (layer_1): Linear(in_features=200, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BinaryClassifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "behind-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "falling-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = TrainDataset(torch.FloatTensor(np.array(X_train, dtype=np.float64)), \n",
    "                          torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "architectural-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = TestDataset(torch.FloatTensor(np.array(X_test, dtype=np.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "charming-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "divided-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fantastic-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010: | Loss: 0.60216 | Acc: 67.263\n",
      "Epoch 020: | Loss: 0.48714 | Acc: 78.526\n",
      "Epoch 030: | Loss: 0.43054 | Acc: 80.526\n",
      "Epoch 040: | Loss: 0.40129 | Acc: 82.474\n",
      "Epoch 050: | Loss: 0.37765 | Acc: 83.474\n",
      "Epoch 060: | Loss: 0.36348 | Acc: 84.105\n",
      "Epoch 070: | Loss: 0.34564 | Acc: 84.632\n",
      "Epoch 080: | Loss: 0.33062 | Acc: 85.632\n",
      "Epoch 090: | Loss: 0.31747 | Acc: 86.632\n",
      "Epoch 100: | Loss: 0.30831 | Acc: 86.526\n",
      "Epoch 110: | Loss: 0.30238 | Acc: 86.684\n",
      "Epoch 120: | Loss: 0.28695 | Acc: 87.579\n",
      "Epoch 130: | Loss: 0.28267 | Acc: 87.842\n",
      "Epoch 140: | Loss: 0.27542 | Acc: 88.211\n",
      "Epoch 150: | Loss: 0.26665 | Acc: 88.895\n",
      "Epoch 160: | Loss: 0.26011 | Acc: 89.368\n",
      "Epoch 170: | Loss: 0.25470 | Acc: 89.526\n",
      "Epoch 180: | Loss: 0.25059 | Acc: 89.737\n",
      "Epoch 190: | Loss: 0.24512 | Acc: 89.474\n",
      "Epoch 200: | Loss: 0.23993 | Acc: 90.000\n",
      "Epoch 210: | Loss: 0.23303 | Acc: 90.737\n",
      "Epoch 220: | Loss: 0.22932 | Acc: 90.895\n",
      "Epoch 230: | Loss: 0.22604 | Acc: 91.000\n",
      "Epoch 240: | Loss: 0.22139 | Acc: 91.421\n",
      "Epoch 250: | Loss: 0.21587 | Acc: 91.684\n",
      "Epoch 260: | Loss: 0.20936 | Acc: 91.474\n",
      "Epoch 270: | Loss: 0.20652 | Acc: 91.842\n",
      "Epoch 280: | Loss: 0.20051 | Acc: 92.579\n",
      "Epoch 290: | Loss: 0.19869 | Acc: 92.316\n",
      "Epoch 300: | Loss: 0.19458 | Acc: 92.684\n",
      "Epoch 310: | Loss: 0.19233 | Acc: 92.632\n",
      "Epoch 320: | Loss: 0.18950 | Acc: 93.316\n",
      "Epoch 330: | Loss: 0.18358 | Acc: 92.632\n",
      "Epoch 340: | Loss: 0.18020 | Acc: 92.947\n",
      "Epoch 350: | Loss: 0.17914 | Acc: 93.211\n",
      "Epoch 360: | Loss: 0.17536 | Acc: 93.211\n",
      "Epoch 370: | Loss: 0.17566 | Acc: 93.842\n",
      "Epoch 380: | Loss: 0.17202 | Acc: 93.474\n",
      "Epoch 390: | Loss: 0.16562 | Acc: 93.789\n",
      "Epoch 400: | Loss: 0.16141 | Acc: 94.105\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "for e in range(1, EPOCHS + 1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    epoch_losses.append(epoch_loss / len(train_loader)) \n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "limiting-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x156d8bd30>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "guilty-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fiscal-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82  32]\n",
      " [ 22 168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75       114\n",
      "           1       0.84      0.88      0.86       190\n",
      "\n",
      "    accuracy                           0.82       304\n",
      "   macro avg       0.81      0.80      0.81       304\n",
      "weighted avg       0.82      0.82      0.82       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_list))\n",
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "painted-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = random.sample(noun_phrases, 1000)\n",
    "X_samples = []\n",
    "for sample in test_samples:\n",
    "    X_samples.append(embeddings[sample.replace(' ', '_')])\n",
    "sample_data = TestDataset(torch.FloatTensor(np.array(X_samples, dtype=np.float64)))\n",
    "sample_loader = DataLoader(dataset=sample_data, batch_size=1)\n",
    "\n",
    "extracted = []\n",
    "not_extracted = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, X_batch in enumerate(sample_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        if y_pred_tag.cpu().numpy()[0][0] == 1:\n",
    "            extracted.append(test_samples[i])\n",
    "        else:\n",
    "            not_extracted.append(test_samples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "monthly-million",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combinations',\n",
       " 'kbrl',\n",
       " 'imagery',\n",
       " 'deep learning techniques',\n",
       " 'motifs',\n",
       " 'each feature',\n",
       " 'then',\n",
       " 'many models',\n",
       " 'positions',\n",
       " 'potts',\n",
       " 'streaming data',\n",
       " 'understanding',\n",
       " 'a local optimum',\n",
       " 'the log softmax',\n",
       " 'she',\n",
       " 'causality',\n",
       " 'words',\n",
       " 'the scene',\n",
       " 'the precision',\n",
       " 'sentiment analysis',\n",
       " 'a large body',\n",
       " 'metric learning',\n",
       " 'the knowledge',\n",
       " 'cho',\n",
       " '2012',\n",
       " 'reranking',\n",
       " 'video',\n",
       " 'neighbors',\n",
       " 'an attention mechanism',\n",
       " 'cost',\n",
       " 'federated',\n",
       " 'capabilities',\n",
       " 'new observations',\n",
       " 'bangla',\n",
       " 'research papers',\n",
       " 'loss of accuracy',\n",
       " 'computer',\n",
       " 'question',\n",
       " 'attentions',\n",
       " 'era',\n",
       " 'multiple levels',\n",
       " 'their environment',\n",
       " 'perception',\n",
       " 'the optimization problem',\n",
       " 'prediction time',\n",
       " 'caption generation',\n",
       " 'deep networks',\n",
       " 'transparency',\n",
       " 'large datasets',\n",
       " 'detections',\n",
       " 'rewards',\n",
       " 'linear projections',\n",
       " 'trends',\n",
       " 'soft constraints',\n",
       " 'probability',\n",
       " 'school',\n",
       " 'pillars',\n",
       " 'neural networks based',\n",
       " 'the problem of image',\n",
       " 'super convergence',\n",
       " 'distributed processing',\n",
       " 'the combination',\n",
       " 'bridge',\n",
       " 'the posterior',\n",
       " 'scene understanding',\n",
       " 'gym',\n",
       " 'mrfs',\n",
       " 'fact',\n",
       " 'layer',\n",
       " 'destination',\n",
       " 'material',\n",
       " 'momentum',\n",
       " 'the dependencies',\n",
       " 'a target domain',\n",
       " 'drivers',\n",
       " 'a distributed representation',\n",
       " 'cilia',\n",
       " 'software',\n",
       " 'the road',\n",
       " 'neighborhood',\n",
       " 'infants',\n",
       " 'the issues',\n",
       " '13',\n",
       " 'partial observability',\n",
       " 'the image',\n",
       " 'generations',\n",
       " 'the events',\n",
       " 'places',\n",
       " 'a memory',\n",
       " 'user interactions',\n",
       " 'parameter learning',\n",
       " 'a bayesian network',\n",
       " 'tissue',\n",
       " 'arl',\n",
       " 'the loss function',\n",
       " 'permutations',\n",
       " 'sims',\n",
       " 'es',\n",
       " 'the input sequence',\n",
       " 'a popular algorithm',\n",
       " 'sentence classification',\n",
       " 'many applications',\n",
       " 'the network size',\n",
       " 'children',\n",
       " 'unanswered',\n",
       " 'prediction accuracy',\n",
       " 'managers',\n",
       " 'dl models',\n",
       " 'mfcc',\n",
       " 'a powerful tool',\n",
       " 'exploitation',\n",
       " 'language modelling',\n",
       " 'detection',\n",
       " 'visual object',\n",
       " 'rr',\n",
       " 'the extraction',\n",
       " 'a bottom',\n",
       " 'the field',\n",
       " 'user preferences',\n",
       " 'model selection',\n",
       " 'delayed',\n",
       " 'proteins',\n",
       " 'neural network architectures',\n",
       " 'each individual',\n",
       " 'a focus',\n",
       " 'companies',\n",
       " 'sparse connectivity',\n",
       " 'crowds',\n",
       " 'genetic algorithms',\n",
       " 'posts',\n",
       " 'archetypes',\n",
       " 'policy',\n",
       " 'policy gradient',\n",
       " 'discretization',\n",
       " 'malware',\n",
       " 'a given task',\n",
       " 'times',\n",
       " 'much attention',\n",
       " 'standard benchmarks',\n",
       " 'powerplay',\n",
       " 'the aim',\n",
       " 'phrases and sentences',\n",
       " 'vision',\n",
       " 'mine',\n",
       " 'sparse representations',\n",
       " 'correlation',\n",
       " 'different contexts',\n",
       " 'remote',\n",
       " 'game',\n",
       " 'real time',\n",
       " 'evidences',\n",
       " 'learning models',\n",
       " 'replacement',\n",
       " 'adoption',\n",
       " 'rate',\n",
       " 'a library',\n",
       " 'contour detection',\n",
       " 'high quality images',\n",
       " 'bayesian network structures',\n",
       " 'wisdom',\n",
       " 'the quasi',\n",
       " 'edge devices',\n",
       " 'wearables',\n",
       " 'patient',\n",
       " 'program',\n",
       " 'new results',\n",
       " 'a great deal',\n",
       " 'prior knowledge',\n",
       " 'clustering tasks',\n",
       " 'dynamical systems',\n",
       " 'external memory',\n",
       " 'binary classification',\n",
       " 'model learning',\n",
       " 'the output layer',\n",
       " 'an extension',\n",
       " 'meek',\n",
       " 'a novel formulation',\n",
       " 'the flexibility',\n",
       " 'both modalities',\n",
       " 'latency',\n",
       " 'automatic speech recognition asr',\n",
       " 'robot navigation',\n",
       " 'locality',\n",
       " 'advertisements',\n",
       " 'mxnet',\n",
       " 'increasing attention',\n",
       " 'maximum likelihood estimation mle',\n",
       " 'a new concept',\n",
       " 'given data set',\n",
       " 'arrays',\n",
       " 'the concept',\n",
       " 'new ones',\n",
       " 'document classification',\n",
       " 'data points',\n",
       " 'communication protocols',\n",
       " 'deployment',\n",
       " 'gcns',\n",
       " 'assistance',\n",
       " 'two aspects',\n",
       " 'similar accuracy',\n",
       " 'polynomial time',\n",
       " 'state of the art classifiers',\n",
       " 'culture',\n",
       " '4',\n",
       " 'the property',\n",
       " 'gssl',\n",
       " 'the quality',\n",
       " 'residuals',\n",
       " 'learning machine elm',\n",
       " 'gibbs sampling',\n",
       " 'text processing',\n",
       " 'natural language generation',\n",
       " 'natural language processing nlp',\n",
       " 'drugs',\n",
       " 'combinatorial optimization',\n",
       " 'signal processing',\n",
       " 'populations',\n",
       " 'other approaches',\n",
       " 'lms',\n",
       " 'slices',\n",
       " 'the promise',\n",
       " 'sparsity',\n",
       " 'genetic algorithm',\n",
       " 'courses',\n",
       " 'bins',\n",
       " 'wikidata',\n",
       " 'kernel learning methods',\n",
       " 'a real time',\n",
       " 'simulated annealing',\n",
       " 'approximate bayesian inference',\n",
       " 'organism',\n",
       " 'the question',\n",
       " 'their variants',\n",
       " 'the art neural networks',\n",
       " 'degree',\n",
       " 'convergence properties',\n",
       " 'sparseness',\n",
       " 'web search',\n",
       " 'pressure',\n",
       " 'sports',\n",
       " 'respect',\n",
       " 'ease',\n",
       " 'promising performance',\n",
       " 'navigation',\n",
       " 'viewpoints',\n",
       " 'differential equations',\n",
       " 'deviations',\n",
       " 'un',\n",
       " 'the latency',\n",
       " 'td lambda',\n",
       " 'a supervised learning problem',\n",
       " 'gradient vanishing',\n",
       " 'generative modeling',\n",
       " 'a loss function',\n",
       " 'costs',\n",
       " 'variational autoencoders',\n",
       " 'a reduction',\n",
       " 'their inputs',\n",
       " 'subspaces',\n",
       " 'various types',\n",
       " 'outcomes',\n",
       " 'prevention',\n",
       " 'occlusions',\n",
       " 'input distributions',\n",
       " 'significance',\n",
       " 'an efficient method',\n",
       " 'fuel',\n",
       " 'knowledge base completion',\n",
       " 'population',\n",
       " 'machine learning ml',\n",
       " 'accuracy',\n",
       " 'growth',\n",
       " 'standard classification',\n",
       " 'the value',\n",
       " 'deals',\n",
       " 'end',\n",
       " 'sparse rewards',\n",
       " 'fuzzy logic',\n",
       " 'its simplicity',\n",
       " 'wanderer',\n",
       " 'imputation',\n",
       " 'robotics',\n",
       " 'certainty',\n",
       " 'expert',\n",
       " 'ddl',\n",
       " 'the diagnosis',\n",
       " 'current practice',\n",
       " 'nlp tasks',\n",
       " 'a unified framework',\n",
       " 'torch',\n",
       " 'data',\n",
       " 'basketball',\n",
       " 'these interactions',\n",
       " 'the purpose',\n",
       " 'two architectures',\n",
       " 'a kernel function',\n",
       " 'the convergence',\n",
       " 'front',\n",
       " 'document',\n",
       " 'robot learning',\n",
       " 'complex tasks',\n",
       " 'item',\n",
       " 'the encoder',\n",
       " 'number',\n",
       " 'the vanishing',\n",
       " 'a patient',\n",
       " 'the novel task',\n",
       " 'payoffs',\n",
       " 'visual stimuli',\n",
       " 'importance sampling',\n",
       " 'control',\n",
       " 'static',\n",
       " 'grammar',\n",
       " 'iii',\n",
       " 'inverse reinforcement learning',\n",
       " 'input',\n",
       " 'pieces',\n",
       " 'a plethora',\n",
       " 'a new perspective',\n",
       " 'the dynamics',\n",
       " 'disentanglement',\n",
       " 'probabilistic reasoning',\n",
       " 'machine learning problems',\n",
       " 'these domains',\n",
       " 'training and evaluation',\n",
       " 'building blocks',\n",
       " 'feed',\n",
       " 'c',\n",
       " 'journals',\n",
       " 'delays',\n",
       " 'the connectivity',\n",
       " 'a hypothesis',\n",
       " 'pragmatics',\n",
       " 'the pixels',\n",
       " 'trustvi',\n",
       " 'density models',\n",
       " 'blogs',\n",
       " 'infty',\n",
       " 'chain graphs',\n",
       " 'dimensions',\n",
       " 'a long history',\n",
       " 'the feedback',\n",
       " 'dimensionality',\n",
       " 'a multi layer',\n",
       " 'the appearance',\n",
       " 'activity',\n",
       " 'feature representations',\n",
       " 'exposure',\n",
       " 'the available data',\n",
       " 'a vector',\n",
       " 'optimization',\n",
       " 'keyword',\n",
       " 'novel applications',\n",
       " 'the ontology',\n",
       " 'a linear transformation',\n",
       " 'transfer learning',\n",
       " 'computer vision tasks',\n",
       " 'distributed representations',\n",
       " 'thousands',\n",
       " 'gpus',\n",
       " 'two challenges',\n",
       " 'estimator',\n",
       " 'modelling',\n",
       " 'partitioning',\n",
       " 'ann',\n",
       " 'the depth',\n",
       " 'a scoring',\n",
       " 'm',\n",
       " 'plenty',\n",
       " 'vulnerability',\n",
       " 'las',\n",
       " 'handwritten digits',\n",
       " 'the attention mechanism',\n",
       " 'interval',\n",
       " 'weeks',\n",
       " 'captions',\n",
       " 'zeros',\n",
       " 'genomics',\n",
       " 'insight',\n",
       " 'hyperparameter optimization',\n",
       " 'variational auto encoders',\n",
       " 'correction',\n",
       " 'vote',\n",
       " 'function',\n",
       " 'textual entailment',\n",
       " 'parameterization',\n",
       " 'caffe',\n",
       " 'fixed points',\n",
       " 'instance',\n",
       " 'several applications',\n",
       " 'probabilistic graphical models',\n",
       " 'adversarial examples',\n",
       " 'dictionary',\n",
       " 'industry and academia',\n",
       " 'the first time',\n",
       " 'moment',\n",
       " 'parameter sharing',\n",
       " 'introspection',\n",
       " 'high dimensional state spaces',\n",
       " 'probability estimates',\n",
       " 'gram',\n",
       " 'other types',\n",
       " 'mobile devices',\n",
       " 'structural properties',\n",
       " 'high level abstractions',\n",
       " 'mason',\n",
       " 'value',\n",
       " 'human pose estimation',\n",
       " 'summarization',\n",
       " 'inclusion',\n",
       " 'the roc curve',\n",
       " 'hand gestures',\n",
       " 'fisher',\n",
       " 'a phenomenon',\n",
       " 'a network architecture',\n",
       " 'large collections',\n",
       " 'many domains',\n",
       " 'possible classes',\n",
       " 'a testbed',\n",
       " 'image processing',\n",
       " 'joint training',\n",
       " 'towers',\n",
       " 'climate',\n",
       " 'the word embeddings',\n",
       " 'sparse learning',\n",
       " 'the progression',\n",
       " 'a practical algorithm',\n",
       " 'brains',\n",
       " 'attention in recent years',\n",
       " 'pattern recognition',\n",
       " 'natural language text',\n",
       " 'tremendous success',\n",
       " 'animals',\n",
       " 'network weights',\n",
       " 'the decisions',\n",
       " 'location',\n",
       " 'characteristics',\n",
       " 'individual words',\n",
       " 'a very large number',\n",
       " 'region',\n",
       " 'diseases',\n",
       " 'boxes',\n",
       " 'platform',\n",
       " 'hypergraph',\n",
       " 'segmentation',\n",
       " 'significant progress',\n",
       " 'bioinformatics',\n",
       " 'atp',\n",
       " 'articles',\n",
       " 'medical',\n",
       " 'text generation',\n",
       " 'latent variable models',\n",
       " 'crowd',\n",
       " 'image representation',\n",
       " 'credit',\n",
       " 'hmms',\n",
       " 'the agent',\n",
       " 'the infinite horizon',\n",
       " 'instructions',\n",
       " 'parallelize',\n",
       " 'textures',\n",
       " 'the boundaries',\n",
       " 'gaze',\n",
       " 'each user',\n",
       " 'event',\n",
       " 'visualization',\n",
       " 'conversations',\n",
       " 'covariate',\n",
       " 'kronecker',\n",
       " 'uncertainties',\n",
       " 'the memory',\n",
       " 'a sentence',\n",
       " 'direction',\n",
       " 'loop',\n",
       " 'characters',\n",
       " 'resolutions',\n",
       " 'a vehicle',\n",
       " 'a subclass',\n",
       " 'sub',\n",
       " 'a wide class',\n",
       " 'gas',\n",
       " 'mnih',\n",
       " 'new tasks',\n",
       " 'partitions',\n",
       " 'natural language processing',\n",
       " 'computer programs',\n",
       " 'computations',\n",
       " 'the curse of dimensionality',\n",
       " 'a general approach',\n",
       " 'bots',\n",
       " 'frames',\n",
       " 'observational data',\n",
       " 'the impact',\n",
       " 'human annotators',\n",
       " 'edge detection',\n",
       " 'autonomy',\n",
       " 'binary classification problems',\n",
       " 'convolutional neural network cnn',\n",
       " 'random forests',\n",
       " 'noisier',\n",
       " 'the first one',\n",
       " 'perception tasks',\n",
       " 'the network parameters',\n",
       " 'scale',\n",
       " 'devices',\n",
       " '2013',\n",
       " 'phones',\n",
       " 'conditioning',\n",
       " 'a theory',\n",
       " 'particles',\n",
       " 'multiple objects',\n",
       " 'the biggest challenges',\n",
       " 'image and sentence',\n",
       " 'inductive logic programming',\n",
       " 'plp',\n",
       " 'iterative methods',\n",
       " 'biomarkers',\n",
       " 'hierarchical clustering',\n",
       " 'preferences',\n",
       " 'a means',\n",
       " 'consideration',\n",
       " 'domain knowledge',\n",
       " 'knowledge representation',\n",
       " 'choice',\n",
       " 'monotonicity',\n",
       " 'an application',\n",
       " 'a classification problem',\n",
       " 'a tensor',\n",
       " 'product',\n",
       " 'machine learning',\n",
       " 'probabilistic programs',\n",
       " 'face',\n",
       " 'sequence labeling tasks',\n",
       " 'measure',\n",
       " 'loopy',\n",
       " 'discriminative learning',\n",
       " 'high accuracy',\n",
       " 'problem sizes',\n",
       " 'data collection',\n",
       " 'ids',\n",
       " 'negative examples',\n",
       " 'great success',\n",
       " 'a fundamental building block',\n",
       " 'annotators',\n",
       " 'abstract concepts',\n",
       " 'representations of data',\n",
       " 'efficacy',\n",
       " 'vanilla',\n",
       " 'repeated',\n",
       " 'thanks',\n",
       " 'occurrences',\n",
       " 'surveillance',\n",
       " 'a practical approach',\n",
       " 'the shortcomings',\n",
       " 'probability densities',\n",
       " 'buildings',\n",
       " 'innovation',\n",
       " 'the factors',\n",
       " 'k',\n",
       " 'counterexample',\n",
       " 'indefinite',\n",
       " 'broad applications',\n",
       " 'big data',\n",
       " 'synonyms',\n",
       " 'someone',\n",
       " 'a bottleneck',\n",
       " 'images and videos',\n",
       " 'language utterances',\n",
       " 'a diverse set',\n",
       " 'the behavior',\n",
       " 'matrix',\n",
       " 'gatys',\n",
       " 'reasons',\n",
       " 'this study',\n",
       " 'our knowledge',\n",
       " 'sea',\n",
       " 'training images',\n",
       " 'localization',\n",
       " 'the construction',\n",
       " 'precision',\n",
       " 'nonlinear transformations',\n",
       " 'noise ratio',\n",
       " 'kws',\n",
       " 'cognitive science',\n",
       " 'colorization',\n",
       " 'model uncertainty',\n",
       " 'the essence',\n",
       " 'setting',\n",
       " 'the exploration',\n",
       " 'play',\n",
       " 'kernel hilbert',\n",
       " 'emotions',\n",
       " 'an external memory',\n",
       " 'pipelines',\n",
       " 'q sigma',\n",
       " 'computation',\n",
       " 'optimal regret',\n",
       " 'many fields',\n",
       " 'each component',\n",
       " 'appearance',\n",
       " 'healthcare',\n",
       " 'the recognition',\n",
       " 'area',\n",
       " 'robots',\n",
       " 'the neural network',\n",
       " 'the occurrence',\n",
       " 'counts',\n",
       " 'adaboost',\n",
       " 'extrinsic',\n",
       " 'missing values',\n",
       " 'optimization problems',\n",
       " 'artificial neural network ann',\n",
       " 'neighbourhood',\n",
       " 'dropout',\n",
       " 'the disease',\n",
       " 'multiple datasets',\n",
       " 'icu',\n",
       " 'the face',\n",
       " 'a framework',\n",
       " 'a collection',\n",
       " 'visual categories',\n",
       " 'learning rates',\n",
       " 'the time',\n",
       " 'existing approaches',\n",
       " 'recognition',\n",
       " 'the movement',\n",
       " 'image search',\n",
       " 'hidden causes',\n",
       " 'a wide variety',\n",
       " 'vector',\n",
       " 'machine learning researchers',\n",
       " 'neural network model',\n",
       " 'topic models',\n",
       " 'visual understanding',\n",
       " 'specialized hardware',\n",
       " 'semantic representations',\n",
       " 'low rank',\n",
       " 'a target',\n",
       " 'high computational complexity',\n",
       " 'verbal',\n",
       " 'evolutionary algorithms',\n",
       " 'motivation',\n",
       " 'intelligence',\n",
       " 'simple gradient',\n",
       " 'each datapoint',\n",
       " 'account',\n",
       " 'concept',\n",
       " 'visual datasets',\n",
       " 'efficiency',\n",
       " 'tags',\n",
       " 'membership',\n",
       " 'the robot',\n",
       " 'archive',\n",
       " 'grading',\n",
       " 'counting',\n",
       " 'run time',\n",
       " 'perceptrons',\n",
       " 'text corpora',\n",
       " 'problem',\n",
       " 'the past years',\n",
       " 'monte carlo',\n",
       " 'average',\n",
       " 'privacy',\n",
       " 'package',\n",
       " 'the words',\n",
       " 'nearest',\n",
       " 'two major challenges',\n",
       " 'the optimal value',\n",
       " 'language identification',\n",
       " 'a novel end',\n",
       " 'j',\n",
       " 'user reviews',\n",
       " 'an adversary',\n",
       " 'an effective strategy',\n",
       " 'advisors',\n",
       " 'semantic parsing',\n",
       " 'a new class',\n",
       " 'volumes',\n",
       " 'a sequence of tasks',\n",
       " 'a sparse representation',\n",
       " 'remarkable results',\n",
       " 'human raters',\n",
       " 'up',\n",
       " 'bernoulli',\n",
       " 'saddle points',\n",
       " 'model accuracy',\n",
       " 'crowdsourcing',\n",
       " 'rbms',\n",
       " 'the way',\n",
       " 'single',\n",
       " 'expert knowledge',\n",
       " 'the sample complexity',\n",
       " 'ntl',\n",
       " 'speech recognition tasks',\n",
       " 'nature',\n",
       " 'large amounts of data',\n",
       " 'iterative algorithms',\n",
       " 'accordance',\n",
       " 'the dialogue',\n",
       " 'corpus',\n",
       " 'mission',\n",
       " 'l2',\n",
       " 'natural language understanding',\n",
       " 'filter',\n",
       " 'fusion',\n",
       " 'gene expression',\n",
       " 'a promising approach',\n",
       " 'b',\n",
       " 'policy learning',\n",
       " 'klog',\n",
       " 'an objective function',\n",
       " 'families',\n",
       " 'grouping',\n",
       " 'a time',\n",
       " 'rbm',\n",
       " 'strengths',\n",
       " 'sequence',\n",
       " 'tensor',\n",
       " 'the messages',\n",
       " 'large scale',\n",
       " 'posteriors',\n",
       " 'room',\n",
       " 'sequence prediction tasks',\n",
       " 'mis',\n",
       " 'reasoning',\n",
       " 'sparse models',\n",
       " 'the content',\n",
       " 'data point',\n",
       " 'galaxies',\n",
       " 'recommender systems',\n",
       " 'speaker',\n",
       " 'human activities',\n",
       " 'focus',\n",
       " 'long sequences',\n",
       " 'computer vision and natural language processing',\n",
       " 'participants',\n",
       " 'a brief introduction',\n",
       " 'questions about images',\n",
       " 'a document',\n",
       " 'aspect',\n",
       " 'entropy regularization',\n",
       " 'solution',\n",
       " 'complex dependencies',\n",
       " 'the number of nodes',\n",
       " 'chemical',\n",
       " 'mart',\n",
       " 'input samples',\n",
       " 'this research',\n",
       " 'parallel',\n",
       " 'cs',\n",
       " 'matrices',\n",
       " 'pools',\n",
       " 'turn',\n",
       " 'classification problems',\n",
       " 'latent structure',\n",
       " 'statistical models',\n",
       " 'coding',\n",
       " 'arguments',\n",
       " 'other domains',\n",
       " 'a compact representation',\n",
       " 'a vocabulary',\n",
       " 'author identification',\n",
       " 'conflict',\n",
       " 'lstms and grus',\n",
       " 'anns',\n",
       " 'multiple classifiers',\n",
       " 'answer',\n",
       " 'a classifier',\n",
       " 'stochastic convex optimization',\n",
       " 'references',\n",
       " 'the detection',\n",
       " 'an effective approach',\n",
       " 'artifacts',\n",
       " 'maximum likelihood estimation',\n",
       " 'smt',\n",
       " 'ai',\n",
       " 'historical data',\n",
       " 'the answer',\n",
       " 'the system']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "integral-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensembles',\n",
       " 'the training data',\n",
       " 'the learning rate',\n",
       " 'the art approaches',\n",
       " 'two tasks',\n",
       " 'impact',\n",
       " 'better',\n",
       " 'convnets',\n",
       " 'most',\n",
       " 'charts',\n",
       " 'speech data',\n",
       " 'the output',\n",
       " 'art',\n",
       " 'four',\n",
       " 'practitioners',\n",
       " 'expectation maximization',\n",
       " 'there',\n",
       " 'the algorithm',\n",
       " 'dynamics',\n",
       " 'they',\n",
       " 'an open challenge',\n",
       " 'short term memory',\n",
       " 'technologies',\n",
       " 'factorization',\n",
       " 'resources',\n",
       " 'these',\n",
       " 'the need',\n",
       " 'the effectiveness',\n",
       " 'important class',\n",
       " 'pu',\n",
       " 'highlights',\n",
       " 'generalization ability',\n",
       " 'the parameters',\n",
       " 'deep q',\n",
       " 'decisions',\n",
       " 'scenarios',\n",
       " 'capturing',\n",
       " 'categories',\n",
       " 'unique challenges',\n",
       " 'theorems',\n",
       " 'the probability distribution',\n",
       " 'the robustness',\n",
       " 'high level tasks',\n",
       " 'bayesian learning',\n",
       " 'solutions',\n",
       " 'latent variables',\n",
       " 'dictionaries',\n",
       " 'need',\n",
       " 'imitation',\n",
       " 'sets',\n",
       " 'recurrent networks',\n",
       " 'anomalies',\n",
       " 'data sparsity',\n",
       " 'the training process',\n",
       " 'irl',\n",
       " 'the accuracy',\n",
       " 'dataset',\n",
       " 'the core',\n",
       " 'superiority',\n",
       " 'the benefits',\n",
       " 'structured outputs',\n",
       " 'samples',\n",
       " 'extracts',\n",
       " 'systems',\n",
       " 'affect',\n",
       " 'work',\n",
       " 'bounds',\n",
       " 'developments',\n",
       " 'ones',\n",
       " 'the values',\n",
       " 'substantial improvements',\n",
       " 'agents',\n",
       " 'hboa',\n",
       " 'different classes',\n",
       " 'studies',\n",
       " 'regions',\n",
       " 'a new family',\n",
       " 'all',\n",
       " 'a variety',\n",
       " 'performance',\n",
       " 'pairs',\n",
       " 'deeper networks',\n",
       " 'massive amounts',\n",
       " 'two issues',\n",
       " 'real world applications',\n",
       " 'ucb',\n",
       " 'works',\n",
       " 'a good',\n",
       " 'proposed models',\n",
       " 'the self',\n",
       " 'large quantities',\n",
       " 'estimators',\n",
       " 'a challenging problem',\n",
       " 'the source',\n",
       " 'the utility',\n",
       " 'deep representations',\n",
       " 'a large amount',\n",
       " 'a unified approach',\n",
       " 'multiple',\n",
       " 'the real world',\n",
       " 'relu',\n",
       " 'a new',\n",
       " 'features',\n",
       " 'this',\n",
       " 'bandit',\n",
       " 'procedures',\n",
       " 'mistakes',\n",
       " 'every day',\n",
       " 'signals',\n",
       " 'corpora',\n",
       " 'the tasks',\n",
       " 'none',\n",
       " 'skills',\n",
       " 'the existence',\n",
       " 'meta learning',\n",
       " 'adaptive',\n",
       " 'outliers',\n",
       " 'their performance',\n",
       " 'the task at hand',\n",
       " 'variables',\n",
       " 'estimate',\n",
       " 'treatments',\n",
       " 'the sense',\n",
       " 'a way',\n",
       " 'datasets',\n",
       " 'particular',\n",
       " 'mislabeled',\n",
       " 'rnn',\n",
       " 'significant improvements',\n",
       " 'mi',\n",
       " 'terms',\n",
       " 'tools',\n",
       " 'the prediction error',\n",
       " 'squares',\n",
       " 'languages',\n",
       " 'hundreds',\n",
       " 'generalizations',\n",
       " 'image text',\n",
       " 'the word',\n",
       " 'factors',\n",
       " 'any',\n",
       " 'link prediction',\n",
       " 'aims',\n",
       " 'better generalization',\n",
       " 'increases',\n",
       " 'embeddings',\n",
       " 'goals',\n",
       " 'a',\n",
       " 'sgan',\n",
       " 'favor',\n",
       " 'simulations',\n",
       " 'aspects',\n",
       " 'advantages',\n",
       " 'fields',\n",
       " 'general',\n",
       " 'paper',\n",
       " 'latent representations',\n",
       " 'their',\n",
       " 'explored',\n",
       " 'dnns',\n",
       " 'compression',\n",
       " 'labeling',\n",
       " 'heuristics',\n",
       " 'a significant amount',\n",
       " 'literature',\n",
       " 'learning systems',\n",
       " 'sequence seq2seq',\n",
       " 'presence',\n",
       " 'prior information',\n",
       " 'inferring',\n",
       " 'topics',\n",
       " 'one language',\n",
       " 'areas',\n",
       " 'magnitude',\n",
       " 'phenomena',\n",
       " 'structured representations',\n",
       " 'extrapolate',\n",
       " 'one',\n",
       " 'others',\n",
       " 'unsupervised',\n",
       " 'the learning process',\n",
       " '1',\n",
       " 'a small subset',\n",
       " 'critic',\n",
       " 'the missing',\n",
       " 'programs',\n",
       " 'the decision maker',\n",
       " 'approaches',\n",
       " 'annotations',\n",
       " 'classification results',\n",
       " 'the key challenges',\n",
       " 'generators',\n",
       " 'challenges',\n",
       " 'best',\n",
       " 'tests',\n",
       " 'action',\n",
       " 'theories',\n",
       " 'the sources',\n",
       " 'component',\n",
       " 'another',\n",
       " 'metrics',\n",
       " 'the models',\n",
       " 'the solutions',\n",
       " 'the equivalence',\n",
       " 'comparison',\n",
       " 'a central role',\n",
       " 'agnostic perturbations',\n",
       " 'the reasoning',\n",
       " 'that',\n",
       " 'the importance',\n",
       " 'purposes',\n",
       " 'rankings',\n",
       " 'results',\n",
       " 'two algorithms',\n",
       " 'the underlying',\n",
       " 'the latent code',\n",
       " 'a self',\n",
       " 'autoencoders',\n",
       " 'accurate predictions',\n",
       " 'speaker verification',\n",
       " 'natural']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "destroyed-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document classification',\n",
       " 'clustering tasks',\n",
       " 'a new perspective',\n",
       " 'the vanishing',\n",
       " 'respect',\n",
       " 'arrays',\n",
       " 'resolutions',\n",
       " 'noisier',\n",
       " 'both modalities',\n",
       " 'game']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "answering-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aims',\n",
       " 'a challenging problem',\n",
       " 'signals',\n",
       " 'samples',\n",
       " 'performance',\n",
       " 'mislabeled',\n",
       " 'accurate predictions',\n",
       " 'advantages',\n",
       " 'areas',\n",
       " 'presence']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(not_extracted, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pem",
   "language": "python",
   "name": "pem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
