{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tested-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classifier implementation (model architecture, training, testing, etc.) derived from\n",
    "#     https://towardsdatascience.com/pytorch-tabular-binary-classification-a0368da5bb89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sixth-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identical-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHRASE_LEN = 6\n",
    "VECTOR_SIZE = 200\n",
    "WINDOW_SIZE = 10\n",
    "NUM_LAYERS = 10\n",
    "\n",
    "MIN_FREQUENCY = 5\n",
    "\n",
    "SHOULD_EXTRACT_NOUN_PHRASES = False\n",
    "SHOULD_GENERATE_UNDERSCORED_CORPUS = False\n",
    "SHOULD_TRAIN_WORD2VEC_MODEL = False\n",
    "\n",
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "solid-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 arxiv abstracts.\n"
     ]
    }
   ],
   "source": [
    "with open('data/arxiv_abstracts_10000.txt', 'r') as f:\n",
    "    arxiv_abstracts = f.read().split('\\n')[:-1]\n",
    "    arxiv_abstracts_raw = '\\n'.join(arxiv_abstracts)\n",
    "    f.close()\n",
    "print(f'Loaded {len(arxiv_abstracts)} arxiv abstracts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjusted-exchange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 672 negative samples.\n"
     ]
    }
   ],
   "source": [
    "negative_samples = pickle.load(open('data/negative_samples.pkl', 'rb'))\n",
    "print(f'Loaded {len(negative_samples)} negative samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "timely-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 672 positive samples.\n"
     ]
    }
   ],
   "source": [
    "positive_samples = pickle.load(open('data/positive_samples.pkl', 'rb'))\n",
    "print(f'Loaded {len(positive_samples)} positive samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "norwegian-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrase(tree_str, label):\n",
    "    phrases = []\n",
    "    trees = Tree.fromstring(tree_str)\n",
    "    for tree in trees:\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == label:\n",
    "                t = subtree\n",
    "                t = ' '.join(t.leaves())\n",
    "                phrases.append(t)\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limiting-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_EXTRACT_NOUN_PHRASES:\n",
    "    nlp = StanfordCoreNLP('data/stanford-corenlp-4.1.0')\n",
    "    noun_phrases = []\n",
    "    for i, abstract in enumerate(arxiv_abstracts):\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Extracting noun phrases from abstract {i + 1} of {len(arxiv_abstracts)}')\n",
    "            pickle.dump(noun_phrases, open('data/noun_phrases.pkl', 'wb'))\n",
    "        try:\n",
    "            tree_str = nlp.parse(abstract)\n",
    "            noun_phrases.extend(extract_phrase(tree_str, 'NP'))\n",
    "        except Exception:\n",
    "            pass\n",
    "    noun_phrases = [np for np in list(set(noun_phrases)) if len(np.split()) <= MAX_PHRASE_LEN]\n",
    "    pickle.dump(noun_phrases, open('data/noun_phrases.pkl', 'wb'))\n",
    "noun_phrases = pickle.load(open('data/noun_phrases.pkl', 'rb'))\n",
    "noun_phrases = [np for np in list(set(noun_phrases)) if len(np.split()) <= MAX_PHRASE_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuous-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phrase_in_corpus(corpus, phrase):\n",
    "    s_idx = corpus.find(phrase)\n",
    "    e_idx = s_idx + len(phrase)\n",
    "    if s_idx != -1 and \\\n",
    "       (s_idx == 0 or corpus[s_idx - 1] in (string.punctuation + ' ')) and \\\n",
    "       (e_idx == len(corpus) or corpus[e_idx] in (string.punctuation + ' ')):\n",
    "        return (s_idx, e_idx)\n",
    "    return (-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flying-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    corpus = arxiv_abstracts_raw[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    for i, positive_sample in enumerate(positive_samples):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Replacing positive_sample {i + 1} of {len(positive_samples)}')\n",
    "        found_indices = set()\n",
    "        while find_phrase_in_corpus(corpus, positive_sample) != (-1, -1) and find_phrase_in_corpus(corpus, positive_sample)[0] not in found_indices:\n",
    "            s_idx, e_idx = find_phrase_in_corpus(corpus, positive_sample)\n",
    "            found_indices.add(s_idx)\n",
    "            corpus = corpus[:s_idx] + positive_sample.replace(' ', '_') + corpus[e_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "talented-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    for i, negative_sample in enumerate(negative_samples):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Replacing negative_sample {i + 1} of {len(negative_samples)}')\n",
    "        found_indices = set()\n",
    "        while find_phrase_in_corpus(corpus, negative_sample) != (-1, -1) and find_phrase_in_corpus(corpus, negative_sample)[0] not in found_indices:\n",
    "            s_idx, e_idx = find_phrase_in_corpus(corpus, negative_sample)\n",
    "            found_indices.add(s_idx)\n",
    "            corpus = corpus[:s_idx] + negative_sample.replace(' ', '_') + corpus[e_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "biological-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    for i, noun_phrase in enumerate(noun_phrases):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Replacing noun_phrase {i + 1} of {len(noun_phrases)}')\n",
    "        found_indices = set()\n",
    "        while find_phrase_in_corpus(corpus, noun_phrase) != (-1, -1) and find_phrase_in_corpus(corpus, noun_phrase)[0] not in found_indices:\n",
    "            s_idx, e_idx = find_phrase_in_corpus(corpus, noun_phrase)\n",
    "            found_indices.add(s_idx)\n",
    "            corpus = corpus[:s_idx] + noun_phrase.replace(' ', '_') + corpus[e_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "injured-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_GENERATE_UNDERSCORED_CORPUS:\n",
    "    pickle.dump(corpus, open('data/underscored_corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "labeled-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "underscored_corpus = pickle.load(open('data/underscored_corpus.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bound-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_TRAIN_WORD2VEC_MODEL:\n",
    "    underscored_corpus_data = []\n",
    "    for i in sent_tokenize(underscored_corpus):\n",
    "        temp = []\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j.lower())\n",
    "        underscored_corpus_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "naval-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_TRAIN_WORD2VEC_MODEL:\n",
    "    word2vec_model = Word2Vec(underscored_corpus_data, min_count=1, window=WINDOW_SIZE, size=VECTOR_SIZE)\n",
    "    word2vec_model.save(f'data/word2vec_model_vs_{VECTOR_SIZE}_ws_{WINDOW_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "selected-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(f'data/word2vec_model_vs_{VECTOR_SIZE}_ws_{WINDOW_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interstate-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in list(word2vec_model.wv.vocab.keys())]\n",
    "embeddings = {token: word2vec_model.wv[token] for token in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "standard-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = [ps for ps in positive_samples if ps.replace(' ', '_') in embeddings and word2vec_model.wv.vocab[ps.replace(' ', '_')].count >= MIN_FREQUENCY]\n",
    "negative_samples = [ns for ns in negative_samples if ns.replace(' ', '_') in embeddings and word2vec_model.wv.vocab[ns.replace(' ', '_')].count >= MIN_FREQUENCY]\n",
    "\n",
    "positive_samples = positive_samples[:min(len(positive_samples), len(negative_samples))]\n",
    "negative_samples = negative_samples[:min(len(positive_samples), len(negative_samples))]\n",
    "\n",
    "ps_set = set(positive_samples)\n",
    "ns_set = set(negative_samples)\n",
    "\n",
    "noun_phrases = [np for np in noun_phrases if np not in ps_set and np not in ns_set and np.replace(' ', '_') in embeddings and word2vec_model.wv.vocab[np.replace(' ', '_')].count >= MIN_FREQUENCY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ultimate-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for phrase in positive_samples:\n",
    "    X.append(embeddings[phrase.replace(' ', '_')])\n",
    "    y.append(1)\n",
    "for phrase in negative_samples:\n",
    "    X.append(embeddings[phrase.replace(' ', '_')])\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "graduate-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X, y))\n",
    "random.shuffle(c)\n",
    "X, y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "boolean-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "amino-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(VECTOR_SIZE, 128)\n",
    "        \n",
    "        self.layers = []\n",
    "        for _ in range(NUM_LAYERS - 1):\n",
    "            self.layers.append(nn.Linear(128, 128))\n",
    "        \n",
    "        self.layer_out = nn.Linear(128, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = self.relu(layer(x))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pregnant-relaxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifier(\n",
       "  (layer_1): Linear(in_features=200, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BinaryClassifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "private-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vertical-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = TrainDataset(torch.FloatTensor(np.array(X_train, dtype=np.float64)), \n",
    "                          torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fifth-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = TestDataset(torch.FloatTensor(np.array(X_test, dtype=np.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "compound-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "living-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "advanced-worth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010: | Loss: 0.69299 | Acc: 50.538\n",
      "Epoch 020: | Loss: 0.69204 | Acc: 51.615\n",
      "Epoch 030: | Loss: 0.69078 | Acc: 51.231\n",
      "Epoch 040: | Loss: 0.68786 | Acc: 51.231\n",
      "Epoch 050: | Loss: 0.68527 | Acc: 51.077\n",
      "Epoch 060: | Loss: 0.68081 | Acc: 68.077\n",
      "Epoch 070: | Loss: 0.67516 | Acc: 65.846\n",
      "Epoch 080: | Loss: 0.67014 | Acc: 66.615\n",
      "Epoch 090: | Loss: 0.66485 | Acc: 65.692\n",
      "Epoch 100: | Loss: 0.65982 | Acc: 66.769\n",
      "Epoch 110: | Loss: 0.65722 | Acc: 65.769\n",
      "Epoch 120: | Loss: 0.64896 | Acc: 67.615\n",
      "Epoch 130: | Loss: 0.64402 | Acc: 66.462\n",
      "Epoch 140: | Loss: 0.63710 | Acc: 65.846\n",
      "Epoch 150: | Loss: 0.63559 | Acc: 65.923\n",
      "Epoch 160: | Loss: 0.63270 | Acc: 66.846\n",
      "Epoch 170: | Loss: 0.62503 | Acc: 67.077\n",
      "Epoch 180: | Loss: 0.62603 | Acc: 65.308\n",
      "Epoch 190: | Loss: 0.61702 | Acc: 66.615\n",
      "Epoch 200: | Loss: 0.61211 | Acc: 68.308\n",
      "Epoch 210: | Loss: 0.61207 | Acc: 68.615\n",
      "Epoch 220: | Loss: 0.61137 | Acc: 66.615\n",
      "Epoch 230: | Loss: 0.60578 | Acc: 68.154\n",
      "Epoch 240: | Loss: 0.59807 | Acc: 67.615\n",
      "Epoch 250: | Loss: 0.59683 | Acc: 68.462\n",
      "Epoch 260: | Loss: 0.59516 | Acc: 68.615\n",
      "Epoch 270: | Loss: 0.60165 | Acc: 67.462\n",
      "Epoch 280: | Loss: 0.59682 | Acc: 66.000\n",
      "Epoch 290: | Loss: 0.60169 | Acc: 67.077\n",
      "Epoch 300: | Loss: 0.58736 | Acc: 69.692\n",
      "Epoch 310: | Loss: 0.59500 | Acc: 67.692\n",
      "Epoch 320: | Loss: 0.58906 | Acc: 67.462\n",
      "Epoch 330: | Loss: 0.57287 | Acc: 69.385\n",
      "Epoch 340: | Loss: 0.57431 | Acc: 69.385\n",
      "Epoch 350: | Loss: 0.57714 | Acc: 69.308\n",
      "Epoch 360: | Loss: 0.57350 | Acc: 69.077\n",
      "Epoch 370: | Loss: 0.57763 | Acc: 69.615\n",
      "Epoch 380: | Loss: 0.57659 | Acc: 68.538\n",
      "Epoch 390: | Loss: 0.57275 | Acc: 71.077\n",
      "Epoch 400: | Loss: 0.57049 | Acc: 70.308\n",
      "Epoch 410: | Loss: 0.57366 | Acc: 68.462\n",
      "Epoch 420: | Loss: 0.56901 | Acc: 69.385\n",
      "Epoch 430: | Loss: 0.57326 | Acc: 69.615\n",
      "Epoch 440: | Loss: 0.56308 | Acc: 70.154\n",
      "Epoch 450: | Loss: 0.55937 | Acc: 70.692\n",
      "Epoch 460: | Loss: 0.55846 | Acc: 69.846\n",
      "Epoch 470: | Loss: 0.55361 | Acc: 69.154\n",
      "Epoch 480: | Loss: 0.55320 | Acc: 70.846\n",
      "Epoch 490: | Loss: 0.55729 | Acc: 69.615\n",
      "Epoch 500: | Loss: 0.55395 | Acc: 71.923\n",
      "Epoch 510: | Loss: 0.55647 | Acc: 70.615\n",
      "Epoch 520: | Loss: 0.55530 | Acc: 71.308\n",
      "Epoch 530: | Loss: 0.55902 | Acc: 70.154\n",
      "Epoch 540: | Loss: 0.54059 | Acc: 71.692\n",
      "Epoch 550: | Loss: 0.53948 | Acc: 71.077\n",
      "Epoch 560: | Loss: 0.54882 | Acc: 69.923\n",
      "Epoch 570: | Loss: 0.54130 | Acc: 71.308\n",
      "Epoch 580: | Loss: 0.53586 | Acc: 71.000\n",
      "Epoch 590: | Loss: 0.53919 | Acc: 72.615\n",
      "Epoch 600: | Loss: 0.53331 | Acc: 71.769\n",
      "Epoch 610: | Loss: 0.53966 | Acc: 71.846\n",
      "Epoch 620: | Loss: 0.53713 | Acc: 70.846\n",
      "Epoch 630: | Loss: 0.54576 | Acc: 70.231\n",
      "Epoch 640: | Loss: 0.53007 | Acc: 72.846\n",
      "Epoch 650: | Loss: 0.53351 | Acc: 71.769\n",
      "Epoch 660: | Loss: 0.53833 | Acc: 70.923\n",
      "Epoch 670: | Loss: 0.52971 | Acc: 71.077\n",
      "Epoch 680: | Loss: 0.51926 | Acc: 73.000\n",
      "Epoch 690: | Loss: 0.53847 | Acc: 71.692\n",
      "Epoch 700: | Loss: 0.52846 | Acc: 71.308\n",
      "Epoch 710: | Loss: 0.52142 | Acc: 73.615\n",
      "Epoch 720: | Loss: 0.51882 | Acc: 74.077\n",
      "Epoch 730: | Loss: 0.52587 | Acc: 73.231\n",
      "Epoch 740: | Loss: 0.52209 | Acc: 72.923\n",
      "Epoch 750: | Loss: 0.52658 | Acc: 73.692\n",
      "Epoch 760: | Loss: 0.52093 | Acc: 72.615\n",
      "Epoch 770: | Loss: 0.52356 | Acc: 73.077\n",
      "Epoch 780: | Loss: 0.51897 | Acc: 72.769\n",
      "Epoch 790: | Loss: 0.51189 | Acc: 74.846\n",
      "Epoch 800: | Loss: 0.50907 | Acc: 73.692\n",
      "Epoch 810: | Loss: 0.51992 | Acc: 73.692\n",
      "Epoch 820: | Loss: 0.51557 | Acc: 73.923\n",
      "Epoch 830: | Loss: 0.51076 | Acc: 75.692\n",
      "Epoch 840: | Loss: 0.50761 | Acc: 75.692\n",
      "Epoch 850: | Loss: 0.50930 | Acc: 74.000\n",
      "Epoch 860: | Loss: 0.50601 | Acc: 73.923\n",
      "Epoch 870: | Loss: 0.50166 | Acc: 75.385\n",
      "Epoch 880: | Loss: 0.50222 | Acc: 73.385\n",
      "Epoch 890: | Loss: 0.50329 | Acc: 75.846\n",
      "Epoch 900: | Loss: 0.50403 | Acc: 74.385\n",
      "Epoch 910: | Loss: 0.51129 | Acc: 74.000\n",
      "Epoch 920: | Loss: 0.50351 | Acc: 73.538\n",
      "Epoch 930: | Loss: 0.50014 | Acc: 74.538\n",
      "Epoch 940: | Loss: 0.48880 | Acc: 77.385\n",
      "Epoch 950: | Loss: 0.49818 | Acc: 74.846\n",
      "Epoch 960: | Loss: 0.49155 | Acc: 77.385\n",
      "Epoch 970: | Loss: 0.48861 | Acc: 75.769\n",
      "Epoch 980: | Loss: 0.47947 | Acc: 76.923\n",
      "Epoch 990: | Loss: 0.49627 | Acc: 75.154\n",
      "Epoch 1000: | Loss: 0.48912 | Acc: 75.615\n",
      "Epoch 1010: | Loss: 0.49539 | Acc: 75.846\n",
      "Epoch 1020: | Loss: 0.49375 | Acc: 76.154\n",
      "Epoch 1030: | Loss: 0.48863 | Acc: 76.769\n",
      "Epoch 1040: | Loss: 0.48934 | Acc: 75.769\n",
      "Epoch 1050: | Loss: 0.49118 | Acc: 76.000\n",
      "Epoch 1060: | Loss: 0.47972 | Acc: 78.000\n",
      "Epoch 1070: | Loss: 0.48334 | Acc: 75.692\n",
      "Epoch 1080: | Loss: 0.49254 | Acc: 76.615\n",
      "Epoch 1090: | Loss: 0.48392 | Acc: 76.846\n",
      "Epoch 1100: | Loss: 0.48456 | Acc: 76.462\n",
      "Epoch 1110: | Loss: 0.47726 | Acc: 77.077\n",
      "Epoch 1120: | Loss: 0.48032 | Acc: 77.231\n",
      "Epoch 1130: | Loss: 0.48155 | Acc: 78.077\n",
      "Epoch 1140: | Loss: 0.47523 | Acc: 76.692\n",
      "Epoch 1150: | Loss: 0.47640 | Acc: 77.538\n",
      "Epoch 1160: | Loss: 0.48660 | Acc: 77.615\n",
      "Epoch 1170: | Loss: 0.46468 | Acc: 80.000\n",
      "Epoch 1180: | Loss: 0.46308 | Acc: 79.000\n",
      "Epoch 1190: | Loss: 0.47405 | Acc: 78.462\n",
      "Epoch 1200: | Loss: 0.46159 | Acc: 78.000\n",
      "Epoch 1210: | Loss: 0.46218 | Acc: 77.615\n",
      "Epoch 1220: | Loss: 0.45874 | Acc: 78.231\n",
      "Epoch 1230: | Loss: 0.45378 | Acc: 79.692\n",
      "Epoch 1240: | Loss: 0.46270 | Acc: 78.000\n",
      "Epoch 1250: | Loss: 0.45238 | Acc: 79.000\n",
      "Epoch 1260: | Loss: 0.44515 | Acc: 80.923\n",
      "Epoch 1270: | Loss: 0.45630 | Acc: 78.308\n",
      "Epoch 1280: | Loss: 0.47141 | Acc: 76.846\n",
      "Epoch 1290: | Loss: 0.45707 | Acc: 78.308\n",
      "Epoch 1300: | Loss: 0.44696 | Acc: 80.462\n",
      "Epoch 1310: | Loss: 0.44861 | Acc: 79.000\n",
      "Epoch 1320: | Loss: 0.44689 | Acc: 80.154\n",
      "Epoch 1330: | Loss: 0.44854 | Acc: 79.308\n",
      "Epoch 1340: | Loss: 0.44844 | Acc: 79.615\n",
      "Epoch 1350: | Loss: 0.45017 | Acc: 79.231\n",
      "Epoch 1360: | Loss: 0.44732 | Acc: 80.846\n",
      "Epoch 1370: | Loss: 0.44180 | Acc: 81.077\n",
      "Epoch 1380: | Loss: 0.44838 | Acc: 79.615\n",
      "Epoch 1390: | Loss: 0.43832 | Acc: 80.462\n",
      "Epoch 1400: | Loss: 0.44846 | Acc: 79.615\n",
      "Epoch 1410: | Loss: 0.44694 | Acc: 79.538\n",
      "Epoch 1420: | Loss: 0.44344 | Acc: 79.923\n",
      "Epoch 1430: | Loss: 0.44001 | Acc: 80.308\n",
      "Epoch 1440: | Loss: 0.43317 | Acc: 82.538\n",
      "Epoch 1450: | Loss: 0.43323 | Acc: 81.923\n",
      "Epoch 1460: | Loss: 0.42989 | Acc: 81.308\n",
      "Epoch 1470: | Loss: 0.43816 | Acc: 80.077\n",
      "Epoch 1480: | Loss: 0.44036 | Acc: 80.846\n",
      "Epoch 1490: | Loss: 0.43927 | Acc: 81.692\n",
      "Epoch 1500: | Loss: 0.43756 | Acc: 80.538\n",
      "Epoch 1510: | Loss: 0.45010 | Acc: 79.769\n",
      "Epoch 1520: | Loss: 0.42504 | Acc: 80.846\n",
      "Epoch 1530: | Loss: 0.43015 | Acc: 80.615\n",
      "Epoch 1540: | Loss: 0.43003 | Acc: 79.846\n",
      "Epoch 1550: | Loss: 0.43423 | Acc: 80.769\n",
      "Epoch 1560: | Loss: 0.43179 | Acc: 81.846\n",
      "Epoch 1570: | Loss: 0.42456 | Acc: 81.000\n",
      "Epoch 1580: | Loss: 0.42293 | Acc: 81.769\n",
      "Epoch 1590: | Loss: 0.41633 | Acc: 82.154\n",
      "Epoch 1600: | Loss: 0.43131 | Acc: 80.077\n",
      "Epoch 1610: | Loss: 0.42518 | Acc: 80.000\n",
      "Epoch 1620: | Loss: 0.42247 | Acc: 81.846\n",
      "Epoch 1630: | Loss: 0.42475 | Acc: 81.077\n",
      "Epoch 1640: | Loss: 0.42963 | Acc: 81.385\n",
      "Epoch 1650: | Loss: 0.42086 | Acc: 81.923\n",
      "Epoch 1660: | Loss: 0.42224 | Acc: 81.692\n",
      "Epoch 1670: | Loss: 0.42336 | Acc: 80.308\n",
      "Epoch 1680: | Loss: 0.43520 | Acc: 80.308\n",
      "Epoch 1690: | Loss: 0.41612 | Acc: 81.846\n",
      "Epoch 1700: | Loss: 0.41971 | Acc: 81.846\n",
      "Epoch 1710: | Loss: 0.41666 | Acc: 83.000\n",
      "Epoch 1720: | Loss: 0.40584 | Acc: 82.462\n",
      "Epoch 1730: | Loss: 0.45107 | Acc: 79.231\n",
      "Epoch 1740: | Loss: 0.41347 | Acc: 82.231\n",
      "Epoch 1750: | Loss: 0.40151 | Acc: 83.769\n",
      "Epoch 1760: | Loss: 0.41049 | Acc: 82.000\n",
      "Epoch 1770: | Loss: 0.40164 | Acc: 83.231\n",
      "Epoch 1780: | Loss: 0.40193 | Acc: 82.538\n",
      "Epoch 1790: | Loss: 0.41478 | Acc: 82.538\n",
      "Epoch 1800: | Loss: 0.41335 | Acc: 81.615\n",
      "Epoch 1810: | Loss: 0.41067 | Acc: 82.154\n",
      "Epoch 1820: | Loss: 0.40831 | Acc: 81.615\n",
      "Epoch 1830: | Loss: 0.40755 | Acc: 82.077\n",
      "Epoch 1840: | Loss: 0.40518 | Acc: 81.846\n",
      "Epoch 1850: | Loss: 0.40470 | Acc: 83.000\n",
      "Epoch 1860: | Loss: 0.40061 | Acc: 82.769\n",
      "Epoch 1870: | Loss: 0.40134 | Acc: 82.077\n",
      "Epoch 1880: | Loss: 0.39442 | Acc: 83.923\n",
      "Epoch 1890: | Loss: 0.41345 | Acc: 81.077\n",
      "Epoch 1900: | Loss: 0.40259 | Acc: 81.385\n",
      "Epoch 1910: | Loss: 0.39298 | Acc: 83.077\n",
      "Epoch 1920: | Loss: 0.38489 | Acc: 83.538\n",
      "Epoch 1930: | Loss: 0.38555 | Acc: 83.692\n",
      "Epoch 1940: | Loss: 0.39715 | Acc: 83.923\n",
      "Epoch 1950: | Loss: 0.40301 | Acc: 81.308\n",
      "Epoch 1960: | Loss: 0.39653 | Acc: 83.077\n",
      "Epoch 1970: | Loss: 0.38607 | Acc: 84.846\n",
      "Epoch 1980: | Loss: 0.40060 | Acc: 80.846\n",
      "Epoch 1990: | Loss: 0.39791 | Acc: 82.462\n",
      "Epoch 2000: | Loss: 0.39522 | Acc: 82.769\n",
      "Epoch 2010: | Loss: 0.38101 | Acc: 81.769\n",
      "Epoch 2020: | Loss: 0.38843 | Acc: 83.846\n",
      "Epoch 2030: | Loss: 0.37704 | Acc: 85.231\n",
      "Epoch 2040: | Loss: 0.39692 | Acc: 81.923\n",
      "Epoch 2050: | Loss: 0.37656 | Acc: 84.846\n",
      "Epoch 2060: | Loss: 0.39449 | Acc: 82.615\n",
      "Epoch 2070: | Loss: 0.39911 | Acc: 82.923\n",
      "Epoch 2080: | Loss: 0.37623 | Acc: 84.462\n",
      "Epoch 2090: | Loss: 0.38083 | Acc: 83.769\n",
      "Epoch 2100: | Loss: 0.38304 | Acc: 82.769\n",
      "Epoch 2110: | Loss: 0.37327 | Acc: 85.077\n",
      "Epoch 2120: | Loss: 0.37897 | Acc: 84.077\n",
      "Epoch 2130: | Loss: 0.37500 | Acc: 84.769\n",
      "Epoch 2140: | Loss: 0.38930 | Acc: 84.077\n",
      "Epoch 2150: | Loss: 0.37994 | Acc: 82.846\n",
      "Epoch 2160: | Loss: 0.37235 | Acc: 84.000\n",
      "Epoch 2170: | Loss: 0.37783 | Acc: 84.154\n",
      "Epoch 2180: | Loss: 0.37618 | Acc: 83.231\n",
      "Epoch 2190: | Loss: 0.37815 | Acc: 83.846\n",
      "Epoch 2200: | Loss: 0.36244 | Acc: 84.615\n",
      "Epoch 2210: | Loss: 0.37277 | Acc: 83.923\n",
      "Epoch 2220: | Loss: 0.37658 | Acc: 83.769\n",
      "Epoch 2230: | Loss: 0.36320 | Acc: 84.615\n",
      "Epoch 2240: | Loss: 0.37131 | Acc: 83.769\n",
      "Epoch 2250: | Loss: 0.36280 | Acc: 84.077\n",
      "Epoch 2260: | Loss: 0.36625 | Acc: 84.769\n",
      "Epoch 2270: | Loss: 0.37202 | Acc: 84.615\n",
      "Epoch 2280: | Loss: 0.36315 | Acc: 85.385\n",
      "Epoch 2290: | Loss: 0.35930 | Acc: 86.000\n",
      "Epoch 2300: | Loss: 0.36278 | Acc: 85.231\n",
      "Epoch 2310: | Loss: 0.38655 | Acc: 83.923\n",
      "Epoch 2320: | Loss: 0.36298 | Acc: 83.923\n",
      "Epoch 2330: | Loss: 0.35948 | Acc: 85.385\n",
      "Epoch 2340: | Loss: 0.39005 | Acc: 84.000\n",
      "Epoch 2350: | Loss: 0.36066 | Acc: 84.846\n",
      "Epoch 2360: | Loss: 0.37235 | Acc: 83.154\n",
      "Epoch 2370: | Loss: 0.36281 | Acc: 85.231\n",
      "Epoch 2380: | Loss: 0.35964 | Acc: 85.077\n",
      "Epoch 2390: | Loss: 0.35601 | Acc: 85.308\n",
      "Epoch 2400: | Loss: 0.35577 | Acc: 85.769\n",
      "Epoch 2410: | Loss: 0.35351 | Acc: 85.385\n",
      "Epoch 2420: | Loss: 0.35759 | Acc: 85.615\n",
      "Epoch 2430: | Loss: 0.35164 | Acc: 84.769\n",
      "Epoch 2440: | Loss: 0.35668 | Acc: 85.077\n",
      "Epoch 2450: | Loss: 0.34493 | Acc: 86.462\n",
      "Epoch 2460: | Loss: 0.35176 | Acc: 84.538\n",
      "Epoch 2470: | Loss: 0.35677 | Acc: 84.923\n",
      "Epoch 2480: | Loss: 0.35385 | Acc: 85.385\n",
      "Epoch 2490: | Loss: 0.35425 | Acc: 85.385\n",
      "Epoch 2500: | Loss: 0.36469 | Acc: 84.769\n",
      "Epoch 2510: | Loss: 0.34119 | Acc: 85.923\n",
      "Epoch 2520: | Loss: 0.34320 | Acc: 86.615\n",
      "Epoch 2530: | Loss: 0.36583 | Acc: 83.231\n",
      "Epoch 2540: | Loss: 0.35117 | Acc: 85.846\n",
      "Epoch 2550: | Loss: 0.34769 | Acc: 85.846\n",
      "Epoch 2560: | Loss: 0.34938 | Acc: 86.077\n",
      "Epoch 2570: | Loss: 0.35237 | Acc: 85.308\n",
      "Epoch 2580: | Loss: 0.33998 | Acc: 86.000\n",
      "Epoch 2590: | Loss: 0.34721 | Acc: 85.923\n",
      "Epoch 2600: | Loss: 0.33960 | Acc: 85.615\n",
      "Epoch 2610: | Loss: 0.36606 | Acc: 83.615\n",
      "Epoch 2620: | Loss: 0.33915 | Acc: 85.462\n",
      "Epoch 2630: | Loss: 0.32520 | Acc: 87.615\n",
      "Epoch 2640: | Loss: 0.35891 | Acc: 86.462\n",
      "Epoch 2650: | Loss: 0.34165 | Acc: 86.846\n",
      "Epoch 2660: | Loss: 0.34703 | Acc: 85.462\n",
      "Epoch 2670: | Loss: 0.34302 | Acc: 85.846\n",
      "Epoch 2680: | Loss: 0.35781 | Acc: 85.077\n",
      "Epoch 2690: | Loss: 0.33604 | Acc: 87.615\n",
      "Epoch 2700: | Loss: 0.32908 | Acc: 86.000\n",
      "Epoch 2710: | Loss: 0.34686 | Acc: 86.154\n",
      "Epoch 2720: | Loss: 0.33401 | Acc: 86.923\n",
      "Epoch 2730: | Loss: 0.34103 | Acc: 86.000\n",
      "Epoch 2740: | Loss: 0.33880 | Acc: 84.923\n",
      "Epoch 2750: | Loss: 0.33451 | Acc: 86.077\n",
      "Epoch 2760: | Loss: 0.33705 | Acc: 86.692\n",
      "Epoch 2770: | Loss: 0.34004 | Acc: 87.154\n",
      "Epoch 2780: | Loss: 0.33510 | Acc: 87.385\n",
      "Epoch 2790: | Loss: 0.33231 | Acc: 85.692\n",
      "Epoch 2800: | Loss: 0.32153 | Acc: 87.615\n",
      "Epoch 2810: | Loss: 0.32806 | Acc: 86.154\n",
      "Epoch 2820: | Loss: 0.33935 | Acc: 86.000\n",
      "Epoch 2830: | Loss: 0.33312 | Acc: 86.154\n",
      "Epoch 2840: | Loss: 0.32927 | Acc: 86.077\n",
      "Epoch 2850: | Loss: 0.32289 | Acc: 87.308\n",
      "Epoch 2860: | Loss: 0.32460 | Acc: 87.615\n",
      "Epoch 2870: | Loss: 0.31622 | Acc: 87.462\n",
      "Epoch 2880: | Loss: 0.32492 | Acc: 86.923\n",
      "Epoch 2890: | Loss: 0.33818 | Acc: 86.154\n",
      "Epoch 2900: | Loss: 0.30756 | Acc: 87.769\n",
      "Epoch 2910: | Loss: 0.33973 | Acc: 86.077\n",
      "Epoch 2920: | Loss: 0.30809 | Acc: 88.231\n",
      "Epoch 2930: | Loss: 0.31940 | Acc: 87.154\n",
      "Epoch 2940: | Loss: 0.31448 | Acc: 87.615\n",
      "Epoch 2950: | Loss: 0.32222 | Acc: 88.154\n",
      "Epoch 2960: | Loss: 0.31355 | Acc: 88.231\n",
      "Epoch 2970: | Loss: 0.32717 | Acc: 87.923\n",
      "Epoch 2980: | Loss: 0.31572 | Acc: 87.538\n",
      "Epoch 2990: | Loss: 0.32781 | Acc: 86.692\n",
      "Epoch 3000: | Loss: 0.32122 | Acc: 87.000\n",
      "Epoch 3010: | Loss: 0.31529 | Acc: 87.846\n",
      "Epoch 3020: | Loss: 0.31922 | Acc: 87.538\n",
      "Epoch 3030: | Loss: 0.30739 | Acc: 86.615\n",
      "Epoch 3040: | Loss: 0.32655 | Acc: 87.615\n",
      "Epoch 3050: | Loss: 0.30689 | Acc: 88.846\n",
      "Epoch 3060: | Loss: 0.30139 | Acc: 88.385\n",
      "Epoch 3070: | Loss: 0.33177 | Acc: 86.538\n",
      "Epoch 3080: | Loss: 0.32141 | Acc: 87.769\n",
      "Epoch 3090: | Loss: 0.31706 | Acc: 88.769\n",
      "Epoch 3100: | Loss: 0.30678 | Acc: 86.846\n",
      "Epoch 3110: | Loss: 0.31941 | Acc: 86.000\n",
      "Epoch 3120: | Loss: 0.30068 | Acc: 88.692\n",
      "Epoch 3130: | Loss: 0.33015 | Acc: 87.231\n",
      "Epoch 3140: | Loss: 0.30416 | Acc: 88.462\n",
      "Epoch 3150: | Loss: 0.30490 | Acc: 89.000\n",
      "Epoch 3160: | Loss: 0.30908 | Acc: 88.000\n",
      "Epoch 3170: | Loss: 0.29882 | Acc: 88.538\n",
      "Epoch 3180: | Loss: 0.31267 | Acc: 87.769\n",
      "Epoch 3190: | Loss: 0.30643 | Acc: 88.692\n",
      "Epoch 3200: | Loss: 0.30681 | Acc: 87.923\n",
      "Epoch 3210: | Loss: 0.31523 | Acc: 87.846\n",
      "Epoch 3220: | Loss: 0.30375 | Acc: 86.769\n",
      "Epoch 3230: | Loss: 0.30190 | Acc: 89.231\n",
      "Epoch 3240: | Loss: 0.31364 | Acc: 88.538\n",
      "Epoch 3250: | Loss: 0.29573 | Acc: 88.308\n",
      "Epoch 3260: | Loss: 0.30405 | Acc: 87.846\n",
      "Epoch 3270: | Loss: 0.31252 | Acc: 88.231\n",
      "Epoch 3280: | Loss: 0.30589 | Acc: 89.308\n",
      "Epoch 3290: | Loss: 0.30534 | Acc: 89.000\n",
      "Epoch 3300: | Loss: 0.30528 | Acc: 88.154\n",
      "Epoch 3310: | Loss: 0.30026 | Acc: 88.000\n",
      "Epoch 3320: | Loss: 0.30657 | Acc: 88.154\n",
      "Epoch 3330: | Loss: 0.31297 | Acc: 86.846\n",
      "Epoch 3340: | Loss: 0.29785 | Acc: 89.308\n",
      "Epoch 3350: | Loss: 0.29502 | Acc: 88.538\n",
      "Epoch 3360: | Loss: 0.30472 | Acc: 89.077\n",
      "Epoch 3370: | Loss: 0.30328 | Acc: 89.538\n",
      "Epoch 3380: | Loss: 0.29143 | Acc: 90.077\n",
      "Epoch 3390: | Loss: 0.30609 | Acc: 87.308\n",
      "Epoch 3400: | Loss: 0.30831 | Acc: 87.923\n",
      "Epoch 3410: | Loss: 0.29231 | Acc: 88.769\n",
      "Epoch 3420: | Loss: 0.30077 | Acc: 87.154\n",
      "Epoch 3430: | Loss: 0.30976 | Acc: 88.000\n",
      "Epoch 3440: | Loss: 0.30440 | Acc: 89.385\n",
      "Epoch 3450: | Loss: 0.29036 | Acc: 89.308\n",
      "Epoch 3460: | Loss: 0.29384 | Acc: 88.615\n",
      "Epoch 3470: | Loss: 0.27661 | Acc: 89.462\n",
      "Epoch 3480: | Loss: 0.28808 | Acc: 88.538\n",
      "Epoch 3490: | Loss: 0.28045 | Acc: 88.462\n",
      "Epoch 3500: | Loss: 0.28424 | Acc: 87.077\n",
      "Epoch 3510: | Loss: 0.28990 | Acc: 88.462\n",
      "Epoch 3520: | Loss: 0.28278 | Acc: 89.077\n",
      "Epoch 3530: | Loss: 0.31533 | Acc: 87.462\n",
      "Epoch 3540: | Loss: 0.29367 | Acc: 88.000\n",
      "Epoch 3550: | Loss: 0.28457 | Acc: 88.692\n",
      "Epoch 3560: | Loss: 0.29070 | Acc: 89.077\n",
      "Epoch 3570: | Loss: 0.27785 | Acc: 89.462\n",
      "Epoch 3580: | Loss: 0.29326 | Acc: 88.231\n",
      "Epoch 3590: | Loss: 0.28854 | Acc: 89.615\n",
      "Epoch 3600: | Loss: 0.28687 | Acc: 89.077\n",
      "Epoch 3610: | Loss: 0.27527 | Acc: 89.923\n",
      "Epoch 3620: | Loss: 0.28951 | Acc: 88.846\n",
      "Epoch 3630: | Loss: 0.27775 | Acc: 89.308\n",
      "Epoch 3640: | Loss: 0.28373 | Acc: 87.692\n",
      "Epoch 3650: | Loss: 0.29168 | Acc: 89.538\n",
      "Epoch 3660: | Loss: 0.29464 | Acc: 88.462\n",
      "Epoch 3670: | Loss: 0.28537 | Acc: 88.846\n",
      "Epoch 3680: | Loss: 0.28506 | Acc: 88.308\n",
      "Epoch 3690: | Loss: 0.27493 | Acc: 90.308\n",
      "Epoch 3700: | Loss: 0.27821 | Acc: 89.231\n",
      "Epoch 3710: | Loss: 0.28062 | Acc: 88.615\n",
      "Epoch 3720: | Loss: 0.26857 | Acc: 90.538\n",
      "Epoch 3730: | Loss: 0.27763 | Acc: 89.385\n",
      "Epoch 3740: | Loss: 0.27590 | Acc: 90.000\n",
      "Epoch 3750: | Loss: 0.29005 | Acc: 87.692\n",
      "Epoch 3760: | Loss: 0.27644 | Acc: 88.846\n",
      "Epoch 3770: | Loss: 0.27108 | Acc: 90.308\n",
      "Epoch 3780: | Loss: 0.26453 | Acc: 90.231\n",
      "Epoch 3790: | Loss: 0.27343 | Acc: 89.538\n",
      "Epoch 3800: | Loss: 0.28658 | Acc: 88.923\n",
      "Epoch 3810: | Loss: 0.26508 | Acc: 90.462\n",
      "Epoch 3820: | Loss: 0.26581 | Acc: 90.692\n",
      "Epoch 3830: | Loss: 0.28455 | Acc: 88.923\n",
      "Epoch 3840: | Loss: 0.27354 | Acc: 90.077\n",
      "Epoch 3850: | Loss: 0.27479 | Acc: 88.077\n",
      "Epoch 3860: | Loss: 0.26065 | Acc: 90.615\n",
      "Epoch 3870: | Loss: 0.25880 | Acc: 91.000\n",
      "Epoch 3880: | Loss: 0.25534 | Acc: 90.615\n",
      "Epoch 3890: | Loss: 0.27321 | Acc: 90.462\n",
      "Epoch 3900: | Loss: 0.25998 | Acc: 90.385\n",
      "Epoch 3910: | Loss: 0.26772 | Acc: 90.154\n",
      "Epoch 3920: | Loss: 0.26299 | Acc: 90.000\n",
      "Epoch 3930: | Loss: 0.26461 | Acc: 90.077\n",
      "Epoch 3940: | Loss: 0.26873 | Acc: 89.154\n",
      "Epoch 3950: | Loss: 0.26222 | Acc: 90.769\n",
      "Epoch 3960: | Loss: 0.27090 | Acc: 89.385\n",
      "Epoch 3970: | Loss: 0.26830 | Acc: 89.615\n",
      "Epoch 3980: | Loss: 0.26346 | Acc: 90.231\n",
      "Epoch 3990: | Loss: 0.25753 | Acc: 90.077\n",
      "Epoch 4000: | Loss: 0.25014 | Acc: 90.462\n",
      "Epoch 4010: | Loss: 0.25611 | Acc: 90.462\n",
      "Epoch 4020: | Loss: 0.25496 | Acc: 90.615\n",
      "Epoch 4030: | Loss: 0.26348 | Acc: 90.538\n",
      "Epoch 4040: | Loss: 0.27243 | Acc: 89.615\n",
      "Epoch 4050: | Loss: 0.25320 | Acc: 91.385\n",
      "Epoch 4060: | Loss: 0.26309 | Acc: 89.769\n",
      "Epoch 4070: | Loss: 0.25539 | Acc: 90.154\n",
      "Epoch 4080: | Loss: 0.26301 | Acc: 90.308\n",
      "Epoch 4090: | Loss: 0.26656 | Acc: 89.385\n",
      "Epoch 4100: | Loss: 0.25792 | Acc: 90.462\n",
      "Epoch 4110: | Loss: 0.24734 | Acc: 90.692\n",
      "Epoch 4120: | Loss: 0.24451 | Acc: 91.538\n",
      "Epoch 4130: | Loss: 0.26790 | Acc: 90.923\n",
      "Epoch 4140: | Loss: 0.25545 | Acc: 90.615\n",
      "Epoch 4150: | Loss: 0.24676 | Acc: 90.538\n",
      "Epoch 4160: | Loss: 0.25166 | Acc: 91.077\n",
      "Epoch 4170: | Loss: 0.25410 | Acc: 90.077\n",
      "Epoch 4180: | Loss: 0.25458 | Acc: 90.923\n",
      "Epoch 4190: | Loss: 0.25679 | Acc: 91.077\n",
      "Epoch 4200: | Loss: 0.24682 | Acc: 91.615\n",
      "Epoch 4210: | Loss: 0.25126 | Acc: 91.077\n",
      "Epoch 4220: | Loss: 0.25013 | Acc: 91.769\n",
      "Epoch 4230: | Loss: 0.25687 | Acc: 90.231\n",
      "Epoch 4240: | Loss: 0.24146 | Acc: 92.000\n",
      "Epoch 4250: | Loss: 0.25191 | Acc: 91.154\n",
      "Epoch 4260: | Loss: 0.25819 | Acc: 89.923\n",
      "Epoch 4270: | Loss: 0.24859 | Acc: 91.385\n",
      "Epoch 4280: | Loss: 0.24353 | Acc: 91.385\n",
      "Epoch 4290: | Loss: 0.25543 | Acc: 90.615\n",
      "Epoch 4300: | Loss: 0.24934 | Acc: 89.923\n",
      "Epoch 4310: | Loss: 0.24614 | Acc: 91.308\n",
      "Epoch 4320: | Loss: 0.26069 | Acc: 89.154\n",
      "Epoch 4330: | Loss: 0.24460 | Acc: 91.231\n",
      "Epoch 4340: | Loss: 0.24749 | Acc: 91.615\n",
      "Epoch 4350: | Loss: 0.23616 | Acc: 92.462\n",
      "Epoch 4360: | Loss: 0.24524 | Acc: 91.308\n",
      "Epoch 4370: | Loss: 0.23357 | Acc: 91.692\n",
      "Epoch 4380: | Loss: 0.25402 | Acc: 91.077\n",
      "Epoch 4390: | Loss: 0.25208 | Acc: 91.077\n",
      "Epoch 4400: | Loss: 0.24382 | Acc: 91.000\n",
      "Epoch 4410: | Loss: 0.23687 | Acc: 91.385\n",
      "Epoch 4420: | Loss: 0.23209 | Acc: 91.385\n",
      "Epoch 4430: | Loss: 0.23720 | Acc: 91.615\n",
      "Epoch 4440: | Loss: 0.25459 | Acc: 90.077\n",
      "Epoch 4450: | Loss: 0.25696 | Acc: 91.000\n",
      "Epoch 4460: | Loss: 0.24006 | Acc: 91.308\n",
      "Epoch 4470: | Loss: 0.24819 | Acc: 91.385\n",
      "Epoch 4480: | Loss: 0.23453 | Acc: 91.154\n",
      "Epoch 4490: | Loss: 0.23157 | Acc: 92.462\n",
      "Epoch 4500: | Loss: 0.24234 | Acc: 91.000\n",
      "Epoch 4510: | Loss: 0.24069 | Acc: 91.000\n",
      "Epoch 4520: | Loss: 0.23538 | Acc: 91.692\n",
      "Epoch 4530: | Loss: 0.23443 | Acc: 92.154\n",
      "Epoch 4540: | Loss: 0.22680 | Acc: 93.231\n",
      "Epoch 4550: | Loss: 0.21991 | Acc: 93.385\n",
      "Epoch 4560: | Loss: 0.24383 | Acc: 91.769\n",
      "Epoch 4570: | Loss: 0.22219 | Acc: 92.538\n",
      "Epoch 4580: | Loss: 0.24926 | Acc: 88.615\n",
      "Epoch 4590: | Loss: 0.23630 | Acc: 91.385\n",
      "Epoch 4600: | Loss: 0.22924 | Acc: 92.846\n",
      "Epoch 4610: | Loss: 0.23516 | Acc: 90.923\n",
      "Epoch 4620: | Loss: 0.21709 | Acc: 92.769\n",
      "Epoch 4630: | Loss: 0.22710 | Acc: 92.769\n",
      "Epoch 4640: | Loss: 0.24247 | Acc: 91.692\n",
      "Epoch 4650: | Loss: 0.21820 | Acc: 92.231\n",
      "Epoch 4660: | Loss: 0.24075 | Acc: 90.231\n",
      "Epoch 4670: | Loss: 0.23265 | Acc: 92.385\n",
      "Epoch 4680: | Loss: 0.22450 | Acc: 91.538\n",
      "Epoch 4690: | Loss: 0.22859 | Acc: 91.769\n",
      "Epoch 4700: | Loss: 0.22428 | Acc: 92.462\n",
      "Epoch 4710: | Loss: 0.23202 | Acc: 91.154\n",
      "Epoch 4720: | Loss: 0.23025 | Acc: 92.154\n",
      "Epoch 4730: | Loss: 0.22723 | Acc: 90.846\n",
      "Epoch 4740: | Loss: 0.22442 | Acc: 92.385\n",
      "Epoch 4750: | Loss: 0.22261 | Acc: 92.000\n",
      "Epoch 4760: | Loss: 0.23467 | Acc: 91.462\n",
      "Epoch 4770: | Loss: 0.23543 | Acc: 91.923\n",
      "Epoch 4780: | Loss: 0.21916 | Acc: 92.538\n",
      "Epoch 4790: | Loss: 0.23554 | Acc: 91.308\n",
      "Epoch 4800: | Loss: 0.23489 | Acc: 91.769\n",
      "Epoch 4810: | Loss: 0.23041 | Acc: 92.077\n",
      "Epoch 4820: | Loss: 0.23750 | Acc: 90.385\n",
      "Epoch 4830: | Loss: 0.22348 | Acc: 92.154\n",
      "Epoch 4840: | Loss: 0.21946 | Acc: 92.308\n",
      "Epoch 4850: | Loss: 0.22344 | Acc: 91.462\n",
      "Epoch 4860: | Loss: 0.21887 | Acc: 91.385\n",
      "Epoch 4870: | Loss: 0.22425 | Acc: 91.769\n",
      "Epoch 4880: | Loss: 0.22878 | Acc: 91.769\n",
      "Epoch 4890: | Loss: 0.22098 | Acc: 92.538\n",
      "Epoch 4900: | Loss: 0.21667 | Acc: 93.077\n",
      "Epoch 4910: | Loss: 0.22256 | Acc: 92.308\n",
      "Epoch 4920: | Loss: 0.22090 | Acc: 93.000\n",
      "Epoch 4930: | Loss: 0.22048 | Acc: 91.692\n",
      "Epoch 4940: | Loss: 0.21647 | Acc: 92.231\n",
      "Epoch 4950: | Loss: 0.21965 | Acc: 92.154\n",
      "Epoch 4960: | Loss: 0.23116 | Acc: 92.923\n",
      "Epoch 4970: | Loss: 0.22436 | Acc: 91.923\n",
      "Epoch 4980: | Loss: 0.21338 | Acc: 92.923\n",
      "Epoch 4990: | Loss: 0.21024 | Acc: 93.154\n",
      "Epoch 5000: | Loss: 0.20308 | Acc: 93.231\n",
      "Epoch 5010: | Loss: 0.23805 | Acc: 91.692\n",
      "Epoch 5020: | Loss: 0.21234 | Acc: 92.385\n",
      "Epoch 5030: | Loss: 0.21125 | Acc: 92.846\n",
      "Epoch 5040: | Loss: 0.22099 | Acc: 91.692\n",
      "Epoch 5050: | Loss: 0.21328 | Acc: 92.462\n",
      "Epoch 5060: | Loss: 0.20702 | Acc: 93.462\n",
      "Epoch 5070: | Loss: 0.20483 | Acc: 93.769\n",
      "Epoch 5080: | Loss: 0.22124 | Acc: 92.385\n",
      "Epoch 5090: | Loss: 0.20518 | Acc: 93.462\n",
      "Epoch 5100: | Loss: 0.20805 | Acc: 93.615\n",
      "Epoch 5110: | Loss: 0.21644 | Acc: 92.846\n",
      "Epoch 5120: | Loss: 0.20756 | Acc: 93.308\n",
      "Epoch 5130: | Loss: 0.20313 | Acc: 93.385\n",
      "Epoch 5140: | Loss: 0.21385 | Acc: 92.692\n",
      "Epoch 5150: | Loss: 0.20753 | Acc: 93.154\n",
      "Epoch 5160: | Loss: 0.22202 | Acc: 91.308\n",
      "Epoch 5170: | Loss: 0.20680 | Acc: 92.923\n",
      "Epoch 5180: | Loss: 0.21816 | Acc: 92.692\n",
      "Epoch 5190: | Loss: 0.20383 | Acc: 93.615\n",
      "Epoch 5200: | Loss: 0.20653 | Acc: 93.000\n",
      "Epoch 5210: | Loss: 0.20425 | Acc: 92.615\n",
      "Epoch 5220: | Loss: 0.22102 | Acc: 91.615\n",
      "Epoch 5230: | Loss: 0.20864 | Acc: 93.000\n",
      "Epoch 5240: | Loss: 0.21086 | Acc: 92.154\n",
      "Epoch 5250: | Loss: 0.21743 | Acc: 91.538\n",
      "Epoch 5260: | Loss: 0.19847 | Acc: 94.231\n",
      "Epoch 5270: | Loss: 0.19351 | Acc: 93.923\n",
      "Epoch 5280: | Loss: 0.21285 | Acc: 92.846\n",
      "Epoch 5290: | Loss: 0.20597 | Acc: 92.462\n",
      "Epoch 5300: | Loss: 0.20333 | Acc: 93.308\n",
      "Epoch 5310: | Loss: 0.20856 | Acc: 92.846\n",
      "Epoch 5320: | Loss: 0.19072 | Acc: 93.846\n",
      "Epoch 5330: | Loss: 0.20515 | Acc: 92.846\n",
      "Epoch 5340: | Loss: 0.20522 | Acc: 93.231\n",
      "Epoch 5350: | Loss: 0.21344 | Acc: 92.385\n",
      "Epoch 5360: | Loss: 0.19039 | Acc: 93.846\n",
      "Epoch 5370: | Loss: 0.19815 | Acc: 93.154\n",
      "Epoch 5380: | Loss: 0.22622 | Acc: 93.077\n",
      "Epoch 5390: | Loss: 0.21531 | Acc: 93.385\n",
      "Epoch 5400: | Loss: 0.20935 | Acc: 92.231\n",
      "Epoch 5410: | Loss: 0.20678 | Acc: 92.538\n",
      "Epoch 5420: | Loss: 0.19804 | Acc: 93.769\n",
      "Epoch 5430: | Loss: 0.19979 | Acc: 93.308\n",
      "Epoch 5440: | Loss: 0.21462 | Acc: 92.692\n",
      "Epoch 5450: | Loss: 0.20740 | Acc: 92.385\n",
      "Epoch 5460: | Loss: 0.20608 | Acc: 93.923\n",
      "Epoch 5470: | Loss: 0.20184 | Acc: 92.846\n",
      "Epoch 5480: | Loss: 0.20238 | Acc: 93.154\n",
      "Epoch 5490: | Loss: 0.18735 | Acc: 94.462\n",
      "Epoch 5500: | Loss: 0.19816 | Acc: 92.923\n",
      "Epoch 5510: | Loss: 0.20280 | Acc: 92.923\n",
      "Epoch 5520: | Loss: 0.19977 | Acc: 92.692\n",
      "Epoch 5530: | Loss: 0.20220 | Acc: 93.077\n",
      "Epoch 5540: | Loss: 0.21044 | Acc: 92.538\n",
      "Epoch 5550: | Loss: 0.20911 | Acc: 93.077\n",
      "Epoch 5560: | Loss: 0.19426 | Acc: 94.231\n",
      "Epoch 5570: | Loss: 0.19496 | Acc: 93.615\n",
      "Epoch 5580: | Loss: 0.19179 | Acc: 93.231\n",
      "Epoch 5590: | Loss: 0.20084 | Acc: 92.462\n",
      "Epoch 5600: | Loss: 0.19811 | Acc: 93.923\n",
      "Epoch 5610: | Loss: 0.19875 | Acc: 92.923\n",
      "Epoch 5620: | Loss: 0.19526 | Acc: 94.154\n",
      "Epoch 5630: | Loss: 0.20179 | Acc: 92.923\n",
      "Epoch 5640: | Loss: 0.20035 | Acc: 93.000\n",
      "Epoch 5650: | Loss: 0.18917 | Acc: 94.769\n",
      "Epoch 5660: | Loss: 0.18162 | Acc: 94.462\n",
      "Epoch 5670: | Loss: 0.18582 | Acc: 94.154\n",
      "Epoch 5680: | Loss: 0.19954 | Acc: 93.692\n",
      "Epoch 5690: | Loss: 0.18994 | Acc: 94.154\n",
      "Epoch 5700: | Loss: 0.19103 | Acc: 94.000\n",
      "Epoch 5710: | Loss: 0.18997 | Acc: 94.385\n",
      "Epoch 5720: | Loss: 0.18684 | Acc: 94.769\n",
      "Epoch 5730: | Loss: 0.18822 | Acc: 94.769\n",
      "Epoch 5740: | Loss: 0.18655 | Acc: 93.692\n",
      "Epoch 5750: | Loss: 0.19631 | Acc: 93.769\n",
      "Epoch 5760: | Loss: 0.18089 | Acc: 94.538\n",
      "Epoch 5770: | Loss: 0.18090 | Acc: 94.846\n",
      "Epoch 5780: | Loss: 0.17946 | Acc: 93.846\n",
      "Epoch 5790: | Loss: 0.19361 | Acc: 93.846\n",
      "Epoch 5800: | Loss: 0.18615 | Acc: 94.077\n",
      "Epoch 5810: | Loss: 0.19507 | Acc: 94.154\n",
      "Epoch 5820: | Loss: 0.19056 | Acc: 93.692\n",
      "Epoch 5830: | Loss: 0.20373 | Acc: 93.231\n",
      "Epoch 5840: | Loss: 0.19688 | Acc: 93.923\n",
      "Epoch 5850: | Loss: 0.18200 | Acc: 94.154\n",
      "Epoch 5860: | Loss: 0.17926 | Acc: 95.000\n",
      "Epoch 5870: | Loss: 0.18573 | Acc: 94.538\n",
      "Epoch 5880: | Loss: 0.17866 | Acc: 93.692\n",
      "Epoch 5890: | Loss: 0.19843 | Acc: 93.308\n",
      "Epoch 5900: | Loss: 0.19668 | Acc: 93.846\n",
      "Epoch 5910: | Loss: 0.18090 | Acc: 94.615\n",
      "Epoch 5920: | Loss: 0.17199 | Acc: 95.000\n",
      "Epoch 5930: | Loss: 0.17901 | Acc: 94.769\n",
      "Epoch 5940: | Loss: 0.19090 | Acc: 94.077\n",
      "Epoch 5950: | Loss: 0.19832 | Acc: 92.692\n",
      "Epoch 5960: | Loss: 0.17691 | Acc: 94.462\n",
      "Epoch 5970: | Loss: 0.18838 | Acc: 94.308\n",
      "Epoch 5980: | Loss: 0.18061 | Acc: 94.385\n",
      "Epoch 5990: | Loss: 0.17726 | Acc: 94.615\n",
      "Epoch 6000: | Loss: 0.17956 | Acc: 94.385\n",
      "Epoch 6010: | Loss: 0.18578 | Acc: 94.538\n",
      "Epoch 6020: | Loss: 0.18112 | Acc: 94.308\n",
      "Epoch 6030: | Loss: 0.17341 | Acc: 94.923\n",
      "Epoch 6040: | Loss: 0.16758 | Acc: 94.231\n",
      "Epoch 6050: | Loss: 0.18441 | Acc: 93.462\n",
      "Epoch 6060: | Loss: 0.19136 | Acc: 93.692\n",
      "Epoch 6070: | Loss: 0.17717 | Acc: 94.462\n",
      "Epoch 6080: | Loss: 0.17591 | Acc: 94.462\n",
      "Epoch 6090: | Loss: 0.18972 | Acc: 94.462\n",
      "Epoch 6100: | Loss: 0.17030 | Acc: 95.462\n",
      "Epoch 6110: | Loss: 0.16960 | Acc: 94.385\n",
      "Epoch 6120: | Loss: 0.17862 | Acc: 94.769\n",
      "Epoch 6130: | Loss: 0.18764 | Acc: 93.000\n",
      "Epoch 6140: | Loss: 0.17960 | Acc: 93.308\n",
      "Epoch 6150: | Loss: 0.18988 | Acc: 94.231\n",
      "Epoch 6160: | Loss: 0.17532 | Acc: 95.077\n",
      "Epoch 6170: | Loss: 0.17171 | Acc: 95.077\n",
      "Epoch 6180: | Loss: 0.17804 | Acc: 93.923\n",
      "Epoch 6190: | Loss: 0.19169 | Acc: 94.077\n",
      "Epoch 6200: | Loss: 0.20057 | Acc: 93.385\n",
      "Epoch 6210: | Loss: 0.17977 | Acc: 94.462\n",
      "Epoch 6220: | Loss: 0.18294 | Acc: 94.308\n",
      "Epoch 6230: | Loss: 0.17578 | Acc: 94.308\n",
      "Epoch 6240: | Loss: 0.15367 | Acc: 95.385\n",
      "Epoch 6250: | Loss: 0.17262 | Acc: 95.000\n",
      "Epoch 6260: | Loss: 0.17894 | Acc: 93.846\n",
      "Epoch 6270: | Loss: 0.16044 | Acc: 95.692\n",
      "Epoch 6280: | Loss: 0.15784 | Acc: 95.462\n",
      "Epoch 6290: | Loss: 0.17513 | Acc: 94.231\n",
      "Epoch 6300: | Loss: 0.18385 | Acc: 94.769\n",
      "Epoch 6310: | Loss: 0.16631 | Acc: 94.692\n",
      "Epoch 6320: | Loss: 0.16817 | Acc: 94.538\n",
      "Epoch 6330: | Loss: 0.16836 | Acc: 94.846\n",
      "Epoch 6340: | Loss: 0.16458 | Acc: 95.692\n",
      "Epoch 6350: | Loss: 0.17023 | Acc: 94.846\n",
      "Epoch 6360: | Loss: 0.16003 | Acc: 95.231\n",
      "Epoch 6370: | Loss: 0.16677 | Acc: 94.923\n",
      "Epoch 6380: | Loss: 0.18007 | Acc: 93.462\n",
      "Epoch 6390: | Loss: 0.16277 | Acc: 95.000\n",
      "Epoch 6400: | Loss: 0.17162 | Acc: 94.385\n",
      "Epoch 6410: | Loss: 0.17059 | Acc: 95.385\n",
      "Epoch 6420: | Loss: 0.17024 | Acc: 94.846\n",
      "Epoch 6430: | Loss: 0.16898 | Acc: 93.846\n",
      "Epoch 6440: | Loss: 0.16684 | Acc: 95.462\n",
      "Epoch 6450: | Loss: 0.16957 | Acc: 95.231\n",
      "Epoch 6460: | Loss: 0.18301 | Acc: 93.692\n",
      "Epoch 6470: | Loss: 0.15852 | Acc: 95.077\n",
      "Epoch 6480: | Loss: 0.17296 | Acc: 94.923\n",
      "Epoch 6490: | Loss: 0.16018 | Acc: 95.692\n",
      "Epoch 6500: | Loss: 0.15377 | Acc: 96.077\n",
      "Epoch 6510: | Loss: 0.15593 | Acc: 95.923\n",
      "Epoch 6520: | Loss: 0.16203 | Acc: 95.538\n",
      "Epoch 6530: | Loss: 0.16653 | Acc: 94.769\n",
      "Epoch 6540: | Loss: 0.16173 | Acc: 95.923\n",
      "Epoch 6550: | Loss: 0.17349 | Acc: 94.462\n",
      "Epoch 6560: | Loss: 0.14637 | Acc: 95.846\n",
      "Epoch 6570: | Loss: 0.16200 | Acc: 94.769\n",
      "Epoch 6580: | Loss: 0.16522 | Acc: 94.692\n",
      "Epoch 6590: | Loss: 0.17431 | Acc: 93.769\n",
      "Epoch 6600: | Loss: 0.15255 | Acc: 95.692\n",
      "Epoch 6610: | Loss: 0.15974 | Acc: 95.538\n",
      "Epoch 6620: | Loss: 0.15484 | Acc: 95.692\n",
      "Epoch 6630: | Loss: 0.16828 | Acc: 94.308\n",
      "Epoch 6640: | Loss: 0.16603 | Acc: 95.000\n",
      "Epoch 6650: | Loss: 0.16318 | Acc: 95.462\n",
      "Epoch 6660: | Loss: 0.16155 | Acc: 94.769\n",
      "Epoch 6670: | Loss: 0.15426 | Acc: 95.769\n",
      "Epoch 6680: | Loss: 0.15346 | Acc: 96.077\n",
      "Epoch 6690: | Loss: 0.16639 | Acc: 95.231\n",
      "Epoch 6700: | Loss: 0.15355 | Acc: 95.385\n",
      "Epoch 6710: | Loss: 0.16011 | Acc: 95.077\n",
      "Epoch 6720: | Loss: 0.16881 | Acc: 95.000\n",
      "Epoch 6730: | Loss: 0.16132 | Acc: 94.077\n",
      "Epoch 6740: | Loss: 0.17050 | Acc: 94.000\n",
      "Epoch 6750: | Loss: 0.16154 | Acc: 95.538\n",
      "Epoch 6760: | Loss: 0.14476 | Acc: 95.923\n",
      "Epoch 6770: | Loss: 0.15590 | Acc: 95.769\n",
      "Epoch 6780: | Loss: 0.15408 | Acc: 94.923\n",
      "Epoch 6790: | Loss: 0.16490 | Acc: 94.615\n",
      "Epoch 6800: | Loss: 0.16189 | Acc: 95.846\n",
      "Epoch 6810: | Loss: 0.14971 | Acc: 95.692\n",
      "Epoch 6820: | Loss: 0.15460 | Acc: 95.385\n",
      "Epoch 6830: | Loss: 0.16377 | Acc: 95.000\n",
      "Epoch 6840: | Loss: 0.15290 | Acc: 94.692\n",
      "Epoch 6850: | Loss: 0.15684 | Acc: 94.538\n",
      "Epoch 6860: | Loss: 0.16569 | Acc: 94.769\n",
      "Epoch 6870: | Loss: 0.14882 | Acc: 96.000\n",
      "Epoch 6880: | Loss: 0.14277 | Acc: 96.154\n",
      "Epoch 6890: | Loss: 0.15703 | Acc: 95.538\n",
      "Epoch 6900: | Loss: 0.15775 | Acc: 94.308\n",
      "Epoch 6910: | Loss: 0.15306 | Acc: 95.538\n",
      "Epoch 6920: | Loss: 0.15920 | Acc: 95.692\n",
      "Epoch 6930: | Loss: 0.15402 | Acc: 95.154\n",
      "Epoch 6940: | Loss: 0.15403 | Acc: 95.077\n",
      "Epoch 6950: | Loss: 0.15237 | Acc: 95.846\n",
      "Epoch 6960: | Loss: 0.14631 | Acc: 96.692\n",
      "Epoch 6970: | Loss: 0.16527 | Acc: 93.692\n",
      "Epoch 6980: | Loss: 0.16499 | Acc: 94.923\n",
      "Epoch 6990: | Loss: 0.14841 | Acc: 96.154\n",
      "Epoch 7000: | Loss: 0.14188 | Acc: 95.615\n",
      "Epoch 7010: | Loss: 0.15121 | Acc: 95.769\n",
      "Epoch 7020: | Loss: 0.13798 | Acc: 95.846\n",
      "Epoch 7030: | Loss: 0.14736 | Acc: 95.846\n",
      "Epoch 7040: | Loss: 0.14103 | Acc: 96.615\n",
      "Epoch 7050: | Loss: 0.14176 | Acc: 95.923\n",
      "Epoch 7060: | Loss: 0.14206 | Acc: 95.615\n",
      "Epoch 7070: | Loss: 0.13540 | Acc: 96.154\n",
      "Epoch 7080: | Loss: 0.14886 | Acc: 95.615\n",
      "Epoch 7090: | Loss: 0.13805 | Acc: 96.077\n",
      "Epoch 7100: | Loss: 0.14350 | Acc: 95.846\n",
      "Epoch 7110: | Loss: 0.15719 | Acc: 95.615\n",
      "Epoch 7120: | Loss: 0.15235 | Acc: 95.000\n",
      "Epoch 7130: | Loss: 0.14474 | Acc: 96.231\n",
      "Epoch 7140: | Loss: 0.14268 | Acc: 95.769\n",
      "Epoch 7150: | Loss: 0.14428 | Acc: 95.923\n",
      "Epoch 7160: | Loss: 0.13877 | Acc: 95.462\n",
      "Epoch 7170: | Loss: 0.15578 | Acc: 95.538\n",
      "Epoch 7180: | Loss: 0.13731 | Acc: 96.462\n",
      "Epoch 7190: | Loss: 0.14382 | Acc: 96.000\n",
      "Epoch 7200: | Loss: 0.14374 | Acc: 95.615\n",
      "Epoch 7210: | Loss: 0.14492 | Acc: 95.769\n",
      "Epoch 7220: | Loss: 0.12973 | Acc: 96.000\n",
      "Epoch 7230: | Loss: 0.14305 | Acc: 95.462\n",
      "Epoch 7240: | Loss: 0.15504 | Acc: 95.692\n",
      "Epoch 7250: | Loss: 0.14260 | Acc: 96.077\n",
      "Epoch 7260: | Loss: 0.13916 | Acc: 95.385\n",
      "Epoch 7270: | Loss: 0.14913 | Acc: 95.308\n",
      "Epoch 7280: | Loss: 0.14324 | Acc: 96.077\n",
      "Epoch 7290: | Loss: 0.14835 | Acc: 96.000\n",
      "Epoch 7300: | Loss: 0.15306 | Acc: 95.308\n",
      "Epoch 7310: | Loss: 0.14710 | Acc: 95.077\n",
      "Epoch 7320: | Loss: 0.14836 | Acc: 95.692\n",
      "Epoch 7330: | Loss: 0.15452 | Acc: 94.923\n",
      "Epoch 7340: | Loss: 0.13712 | Acc: 95.538\n",
      "Epoch 7350: | Loss: 0.14196 | Acc: 95.462\n",
      "Epoch 7360: | Loss: 0.13321 | Acc: 96.231\n",
      "Epoch 7370: | Loss: 0.14758 | Acc: 95.615\n",
      "Epoch 7380: | Loss: 0.15423 | Acc: 95.385\n",
      "Epoch 7390: | Loss: 0.14719 | Acc: 95.000\n",
      "Epoch 7400: | Loss: 0.12929 | Acc: 96.462\n",
      "Epoch 7410: | Loss: 0.13130 | Acc: 96.846\n",
      "Epoch 7420: | Loss: 0.15456 | Acc: 95.385\n",
      "Epoch 7430: | Loss: 0.15023 | Acc: 95.462\n",
      "Epoch 7440: | Loss: 0.13039 | Acc: 96.846\n",
      "Epoch 7450: | Loss: 0.13655 | Acc: 96.077\n",
      "Epoch 7460: | Loss: 0.13106 | Acc: 96.462\n",
      "Epoch 7470: | Loss: 0.13998 | Acc: 96.308\n",
      "Epoch 7480: | Loss: 0.13864 | Acc: 96.308\n",
      "Epoch 7490: | Loss: 0.13530 | Acc: 96.154\n",
      "Epoch 7500: | Loss: 0.14188 | Acc: 95.154\n",
      "Epoch 7510: | Loss: 0.13766 | Acc: 95.692\n",
      "Epoch 7520: | Loss: 0.13574 | Acc: 96.308\n",
      "Epoch 7530: | Loss: 0.14252 | Acc: 95.538\n",
      "Epoch 7540: | Loss: 0.13156 | Acc: 96.385\n",
      "Epoch 7550: | Loss: 0.13622 | Acc: 95.769\n",
      "Epoch 7560: | Loss: 0.14972 | Acc: 95.538\n",
      "Epoch 7570: | Loss: 0.12822 | Acc: 96.846\n",
      "Epoch 7580: | Loss: 0.13508 | Acc: 95.615\n",
      "Epoch 7590: | Loss: 0.13030 | Acc: 97.231\n",
      "Epoch 7600: | Loss: 0.13392 | Acc: 96.154\n",
      "Epoch 7610: | Loss: 0.13942 | Acc: 95.385\n",
      "Epoch 7620: | Loss: 0.13735 | Acc: 95.308\n",
      "Epoch 7630: | Loss: 0.13115 | Acc: 95.923\n",
      "Epoch 7640: | Loss: 0.12943 | Acc: 95.923\n",
      "Epoch 7650: | Loss: 0.12503 | Acc: 97.154\n",
      "Epoch 7660: | Loss: 0.13043 | Acc: 96.231\n",
      "Epoch 7670: | Loss: 0.12306 | Acc: 96.769\n",
      "Epoch 7680: | Loss: 0.13090 | Acc: 96.077\n",
      "Epoch 7690: | Loss: 0.13663 | Acc: 96.000\n",
      "Epoch 7700: | Loss: 0.13819 | Acc: 95.846\n",
      "Epoch 7710: | Loss: 0.13407 | Acc: 96.000\n",
      "Epoch 7720: | Loss: 0.13592 | Acc: 96.154\n",
      "Epoch 7730: | Loss: 0.13476 | Acc: 96.000\n",
      "Epoch 7740: | Loss: 0.12584 | Acc: 96.923\n",
      "Epoch 7750: | Loss: 0.11966 | Acc: 96.308\n",
      "Epoch 7760: | Loss: 0.13015 | Acc: 97.000\n",
      "Epoch 7770: | Loss: 0.12049 | Acc: 97.231\n",
      "Epoch 7780: | Loss: 0.13894 | Acc: 96.000\n",
      "Epoch 7790: | Loss: 0.13470 | Acc: 96.615\n",
      "Epoch 7800: | Loss: 0.14143 | Acc: 95.231\n",
      "Epoch 7810: | Loss: 0.12089 | Acc: 96.692\n",
      "Epoch 7820: | Loss: 0.14761 | Acc: 96.154\n",
      "Epoch 7830: | Loss: 0.14334 | Acc: 96.154\n",
      "Epoch 7840: | Loss: 0.12278 | Acc: 96.462\n",
      "Epoch 7850: | Loss: 0.14226 | Acc: 96.000\n",
      "Epoch 7860: | Loss: 0.13345 | Acc: 95.692\n",
      "Epoch 7870: | Loss: 0.13624 | Acc: 95.462\n",
      "Epoch 7880: | Loss: 0.13211 | Acc: 96.077\n",
      "Epoch 7890: | Loss: 0.12763 | Acc: 96.000\n",
      "Epoch 7900: | Loss: 0.11837 | Acc: 96.538\n",
      "Epoch 7910: | Loss: 0.12075 | Acc: 96.385\n",
      "Epoch 7920: | Loss: 0.11960 | Acc: 96.000\n",
      "Epoch 7930: | Loss: 0.13166 | Acc: 95.923\n",
      "Epoch 7940: | Loss: 0.12596 | Acc: 95.692\n",
      "Epoch 7950: | Loss: 0.13653 | Acc: 96.000\n",
      "Epoch 7960: | Loss: 0.12189 | Acc: 95.923\n",
      "Epoch 7970: | Loss: 0.14148 | Acc: 96.231\n",
      "Epoch 7980: | Loss: 0.11815 | Acc: 96.769\n",
      "Epoch 7990: | Loss: 0.15029 | Acc: 95.077\n",
      "Epoch 8000: | Loss: 0.12441 | Acc: 96.538\n",
      "Epoch 8010: | Loss: 0.12297 | Acc: 97.000\n",
      "Epoch 8020: | Loss: 0.12128 | Acc: 97.000\n",
      "Epoch 8030: | Loss: 0.12675 | Acc: 96.385\n",
      "Epoch 8040: | Loss: 0.12553 | Acc: 97.000\n",
      "Epoch 8050: | Loss: 0.13551 | Acc: 95.385\n",
      "Epoch 8060: | Loss: 0.12679 | Acc: 96.385\n",
      "Epoch 8070: | Loss: 0.11305 | Acc: 96.692\n",
      "Epoch 8080: | Loss: 0.11229 | Acc: 97.154\n",
      "Epoch 8090: | Loss: 0.12508 | Acc: 96.615\n",
      "Epoch 8100: | Loss: 0.12217 | Acc: 96.923\n",
      "Epoch 8110: | Loss: 0.11016 | Acc: 96.923\n",
      "Epoch 8120: | Loss: 0.12901 | Acc: 96.462\n",
      "Epoch 8130: | Loss: 0.12157 | Acc: 96.538\n",
      "Epoch 8140: | Loss: 0.11552 | Acc: 97.077\n",
      "Epoch 8150: | Loss: 0.12425 | Acc: 96.615\n",
      "Epoch 8160: | Loss: 0.13220 | Acc: 95.846\n",
      "Epoch 8170: | Loss: 0.12698 | Acc: 96.077\n",
      "Epoch 8180: | Loss: 0.12062 | Acc: 96.385\n",
      "Epoch 8190: | Loss: 0.11356 | Acc: 96.385\n",
      "Epoch 8200: | Loss: 0.12357 | Acc: 96.231\n",
      "Epoch 8210: | Loss: 0.11852 | Acc: 97.077\n",
      "Epoch 8220: | Loss: 0.11588 | Acc: 96.462\n",
      "Epoch 8230: | Loss: 0.11776 | Acc: 96.231\n",
      "Epoch 8240: | Loss: 0.11614 | Acc: 97.000\n",
      "Epoch 8250: | Loss: 0.11473 | Acc: 97.231\n",
      "Epoch 8260: | Loss: 0.11644 | Acc: 96.308\n",
      "Epoch 8270: | Loss: 0.10741 | Acc: 97.308\n",
      "Epoch 8280: | Loss: 0.12013 | Acc: 97.154\n",
      "Epoch 8290: | Loss: 0.11762 | Acc: 96.846\n",
      "Epoch 8300: | Loss: 0.11995 | Acc: 96.154\n",
      "Epoch 8310: | Loss: 0.11999 | Acc: 96.769\n",
      "Epoch 8320: | Loss: 0.12627 | Acc: 96.231\n",
      "Epoch 8330: | Loss: 0.12259 | Acc: 96.538\n",
      "Epoch 8340: | Loss: 0.11491 | Acc: 96.538\n",
      "Epoch 8350: | Loss: 0.11163 | Acc: 97.000\n",
      "Epoch 8360: | Loss: 0.10633 | Acc: 97.000\n",
      "Epoch 8370: | Loss: 0.12763 | Acc: 96.077\n",
      "Epoch 8380: | Loss: 0.11269 | Acc: 97.231\n",
      "Epoch 8390: | Loss: 0.12453 | Acc: 96.385\n",
      "Epoch 8400: | Loss: 0.12669 | Acc: 95.846\n",
      "Epoch 8410: | Loss: 0.12174 | Acc: 96.538\n",
      "Epoch 8420: | Loss: 0.12650 | Acc: 96.846\n",
      "Epoch 8430: | Loss: 0.10894 | Acc: 97.462\n",
      "Epoch 8440: | Loss: 0.11486 | Acc: 96.308\n",
      "Epoch 8450: | Loss: 0.11273 | Acc: 96.692\n",
      "Epoch 8460: | Loss: 0.10724 | Acc: 96.923\n",
      "Epoch 8470: | Loss: 0.12669 | Acc: 96.692\n",
      "Epoch 8480: | Loss: 0.11504 | Acc: 96.154\n",
      "Epoch 8490: | Loss: 0.10948 | Acc: 97.231\n",
      "Epoch 8500: | Loss: 0.11489 | Acc: 97.308\n",
      "Epoch 8510: | Loss: 0.10883 | Acc: 97.231\n",
      "Epoch 8520: | Loss: 0.12147 | Acc: 96.615\n",
      "Epoch 8530: | Loss: 0.10772 | Acc: 96.769\n",
      "Epoch 8540: | Loss: 0.11665 | Acc: 96.615\n",
      "Epoch 8550: | Loss: 0.10644 | Acc: 97.538\n",
      "Epoch 8560: | Loss: 0.11421 | Acc: 96.923\n",
      "Epoch 8570: | Loss: 0.10857 | Acc: 97.077\n",
      "Epoch 8580: | Loss: 0.10684 | Acc: 97.000\n",
      "Epoch 8590: | Loss: 0.10399 | Acc: 96.846\n",
      "Epoch 8600: | Loss: 0.10989 | Acc: 96.769\n",
      "Epoch 8610: | Loss: 0.11236 | Acc: 96.923\n",
      "Epoch 8620: | Loss: 0.11063 | Acc: 96.923\n",
      "Epoch 8630: | Loss: 0.11487 | Acc: 96.000\n",
      "Epoch 8640: | Loss: 0.09705 | Acc: 97.923\n",
      "Epoch 8650: | Loss: 0.11054 | Acc: 97.154\n",
      "Epoch 8660: | Loss: 0.11276 | Acc: 96.538\n",
      "Epoch 8670: | Loss: 0.11911 | Acc: 96.846\n",
      "Epoch 8680: | Loss: 0.10664 | Acc: 97.692\n",
      "Epoch 8690: | Loss: 0.10478 | Acc: 97.000\n",
      "Epoch 8700: | Loss: 0.09660 | Acc: 97.385\n",
      "Epoch 8710: | Loss: 0.10945 | Acc: 97.385\n",
      "Epoch 8720: | Loss: 0.10348 | Acc: 96.923\n",
      "Epoch 8730: | Loss: 0.10023 | Acc: 97.308\n",
      "Epoch 8740: | Loss: 0.10682 | Acc: 97.692\n",
      "Epoch 8750: | Loss: 0.12018 | Acc: 96.846\n",
      "Epoch 8760: | Loss: 0.10877 | Acc: 96.923\n",
      "Epoch 8770: | Loss: 0.10611 | Acc: 97.231\n",
      "Epoch 8780: | Loss: 0.09935 | Acc: 97.615\n",
      "Epoch 8790: | Loss: 0.10437 | Acc: 97.462\n",
      "Epoch 8800: | Loss: 0.10087 | Acc: 97.308\n",
      "Epoch 8810: | Loss: 0.10831 | Acc: 96.692\n",
      "Epoch 8820: | Loss: 0.10458 | Acc: 97.308\n",
      "Epoch 8830: | Loss: 0.09225 | Acc: 97.692\n",
      "Epoch 8840: | Loss: 0.10449 | Acc: 97.231\n",
      "Epoch 8850: | Loss: 0.09823 | Acc: 96.692\n",
      "Epoch 8860: | Loss: 0.11712 | Acc: 96.923\n",
      "Epoch 8870: | Loss: 0.11068 | Acc: 96.462\n",
      "Epoch 8880: | Loss: 0.10480 | Acc: 97.615\n",
      "Epoch 8890: | Loss: 0.10490 | Acc: 97.615\n",
      "Epoch 8900: | Loss: 0.10914 | Acc: 97.000\n",
      "Epoch 8910: | Loss: 0.11385 | Acc: 96.769\n",
      "Epoch 8920: | Loss: 0.12855 | Acc: 96.923\n",
      "Epoch 8930: | Loss: 0.11254 | Acc: 96.846\n",
      "Epoch 8940: | Loss: 0.10466 | Acc: 96.846\n",
      "Epoch 8950: | Loss: 0.11234 | Acc: 97.000\n",
      "Epoch 8960: | Loss: 0.09705 | Acc: 97.308\n",
      "Epoch 8970: | Loss: 0.10001 | Acc: 97.231\n",
      "Epoch 8980: | Loss: 0.10975 | Acc: 97.385\n",
      "Epoch 8990: | Loss: 0.09408 | Acc: 97.692\n",
      "Epoch 9000: | Loss: 0.10528 | Acc: 96.923\n",
      "Epoch 9010: | Loss: 0.10399 | Acc: 97.538\n",
      "Epoch 9020: | Loss: 0.10699 | Acc: 96.538\n",
      "Epoch 9030: | Loss: 0.09827 | Acc: 97.308\n",
      "Epoch 9040: | Loss: 0.10292 | Acc: 97.385\n",
      "Epoch 9050: | Loss: 0.09917 | Acc: 97.462\n",
      "Epoch 9060: | Loss: 0.10165 | Acc: 96.923\n",
      "Epoch 9070: | Loss: 0.09002 | Acc: 97.615\n",
      "Epoch 9080: | Loss: 0.09223 | Acc: 97.385\n",
      "Epoch 9090: | Loss: 0.10605 | Acc: 96.692\n",
      "Epoch 9100: | Loss: 0.10041 | Acc: 97.077\n",
      "Epoch 9110: | Loss: 0.10337 | Acc: 97.308\n",
      "Epoch 9120: | Loss: 0.09966 | Acc: 97.538\n",
      "Epoch 9130: | Loss: 0.10824 | Acc: 96.615\n",
      "Epoch 9140: | Loss: 0.10579 | Acc: 97.154\n",
      "Epoch 9150: | Loss: 0.09638 | Acc: 97.385\n",
      "Epoch 9160: | Loss: 0.09925 | Acc: 97.000\n",
      "Epoch 9170: | Loss: 0.09905 | Acc: 97.154\n",
      "Epoch 9180: | Loss: 0.09084 | Acc: 97.769\n",
      "Epoch 9190: | Loss: 0.09440 | Acc: 98.000\n",
      "Epoch 9200: | Loss: 0.10719 | Acc: 97.385\n",
      "Epoch 9210: | Loss: 0.09362 | Acc: 97.154\n",
      "Epoch 9220: | Loss: 0.10198 | Acc: 97.308\n",
      "Epoch 9230: | Loss: 0.10182 | Acc: 97.231\n",
      "Epoch 9240: | Loss: 0.09170 | Acc: 97.769\n",
      "Epoch 9250: | Loss: 0.10106 | Acc: 97.615\n",
      "Epoch 9260: | Loss: 0.10064 | Acc: 97.385\n",
      "Epoch 9270: | Loss: 0.09126 | Acc: 97.692\n",
      "Epoch 9280: | Loss: 0.10256 | Acc: 96.846\n",
      "Epoch 9290: | Loss: 0.11557 | Acc: 96.077\n",
      "Epoch 9300: | Loss: 0.10717 | Acc: 96.692\n",
      "Epoch 9310: | Loss: 0.11662 | Acc: 97.231\n",
      "Epoch 9320: | Loss: 0.09221 | Acc: 97.769\n",
      "Epoch 9330: | Loss: 0.09867 | Acc: 97.846\n",
      "Epoch 9340: | Loss: 0.08905 | Acc: 97.923\n",
      "Epoch 9350: | Loss: 0.10190 | Acc: 97.231\n",
      "Epoch 9360: | Loss: 0.11599 | Acc: 97.462\n",
      "Epoch 9370: | Loss: 0.09719 | Acc: 97.538\n",
      "Epoch 9380: | Loss: 0.09065 | Acc: 97.923\n",
      "Epoch 9390: | Loss: 0.10134 | Acc: 96.538\n",
      "Epoch 9400: | Loss: 0.09703 | Acc: 96.923\n",
      "Epoch 9410: | Loss: 0.09158 | Acc: 96.923\n",
      "Epoch 9420: | Loss: 0.08940 | Acc: 97.692\n",
      "Epoch 9430: | Loss: 0.09477 | Acc: 96.769\n",
      "Epoch 9440: | Loss: 0.10668 | Acc: 97.077\n",
      "Epoch 9450: | Loss: 0.09828 | Acc: 97.308\n",
      "Epoch 9460: | Loss: 0.08695 | Acc: 97.462\n",
      "Epoch 9470: | Loss: 0.10976 | Acc: 97.000\n",
      "Epoch 9480: | Loss: 0.09343 | Acc: 97.692\n",
      "Epoch 9490: | Loss: 0.09157 | Acc: 97.692\n",
      "Epoch 9500: | Loss: 0.09462 | Acc: 97.538\n",
      "Epoch 9510: | Loss: 0.09430 | Acc: 97.846\n",
      "Epoch 9520: | Loss: 0.09608 | Acc: 97.615\n",
      "Epoch 9530: | Loss: 0.09700 | Acc: 96.538\n",
      "Epoch 9540: | Loss: 0.09883 | Acc: 97.462\n",
      "Epoch 9550: | Loss: 0.08873 | Acc: 97.462\n",
      "Epoch 9560: | Loss: 0.09047 | Acc: 97.538\n",
      "Epoch 9570: | Loss: 0.09243 | Acc: 97.846\n",
      "Epoch 9580: | Loss: 0.09247 | Acc: 97.846\n",
      "Epoch 9590: | Loss: 0.10265 | Acc: 97.000\n",
      "Epoch 9600: | Loss: 0.09699 | Acc: 97.308\n",
      "Epoch 9610: | Loss: 0.08674 | Acc: 97.154\n",
      "Epoch 9620: | Loss: 0.08957 | Acc: 97.462\n",
      "Epoch 9630: | Loss: 0.10003 | Acc: 96.846\n",
      "Epoch 9640: | Loss: 0.09516 | Acc: 97.385\n",
      "Epoch 9650: | Loss: 0.07810 | Acc: 98.231\n",
      "Epoch 9660: | Loss: 0.08338 | Acc: 97.846\n",
      "Epoch 9670: | Loss: 0.09626 | Acc: 97.000\n",
      "Epoch 9680: | Loss: 0.08842 | Acc: 97.846\n",
      "Epoch 9690: | Loss: 0.10205 | Acc: 97.154\n",
      "Epoch 9700: | Loss: 0.08549 | Acc: 97.923\n",
      "Epoch 9710: | Loss: 0.08921 | Acc: 97.615\n",
      "Epoch 9720: | Loss: 0.09207 | Acc: 97.615\n",
      "Epoch 9730: | Loss: 0.09235 | Acc: 97.308\n",
      "Epoch 9740: | Loss: 0.10620 | Acc: 96.231\n",
      "Epoch 9750: | Loss: 0.08537 | Acc: 97.692\n",
      "Epoch 9760: | Loss: 0.08322 | Acc: 98.231\n",
      "Epoch 9770: | Loss: 0.09329 | Acc: 97.077\n",
      "Epoch 9780: | Loss: 0.09367 | Acc: 97.462\n",
      "Epoch 9790: | Loss: 0.08834 | Acc: 97.846\n",
      "Epoch 9800: | Loss: 0.11002 | Acc: 96.692\n",
      "Epoch 9810: | Loss: 0.08249 | Acc: 98.000\n",
      "Epoch 9820: | Loss: 0.09431 | Acc: 97.231\n",
      "Epoch 9830: | Loss: 0.08289 | Acc: 98.000\n",
      "Epoch 9840: | Loss: 0.08353 | Acc: 98.000\n",
      "Epoch 9850: | Loss: 0.08064 | Acc: 97.692\n",
      "Epoch 9860: | Loss: 0.07905 | Acc: 98.308\n",
      "Epoch 9870: | Loss: 0.07953 | Acc: 98.385\n",
      "Epoch 9880: | Loss: 0.08217 | Acc: 97.923\n",
      "Epoch 9890: | Loss: 0.08133 | Acc: 98.231\n",
      "Epoch 9900: | Loss: 0.09195 | Acc: 96.923\n",
      "Epoch 9910: | Loss: 0.09331 | Acc: 97.846\n",
      "Epoch 9920: | Loss: 0.07930 | Acc: 97.923\n",
      "Epoch 9930: | Loss: 0.08005 | Acc: 97.231\n",
      "Epoch 9940: | Loss: 0.09306 | Acc: 97.308\n",
      "Epoch 9950: | Loss: 0.08581 | Acc: 97.846\n",
      "Epoch 9960: | Loss: 0.08139 | Acc: 98.154\n",
      "Epoch 9970: | Loss: 0.08658 | Acc: 97.538\n",
      "Epoch 9980: | Loss: 0.08346 | Acc: 97.615\n",
      "Epoch 9990: | Loss: 0.07343 | Acc: 98.154\n",
      "Epoch 10000: | Loss: 0.08424 | Acc: 97.769\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "for e in range(1, EPOCHS + 1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    epoch_losses.append(epoch_loss / len(train_loader)) \n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "working-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffbce2baac0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "straight-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "loose-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97  8]\n",
      " [23 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       105\n",
      "           1       0.89      0.75      0.81        91\n",
      "\n",
      "    accuracy                           0.84       196\n",
      "   macro avg       0.85      0.84      0.84       196\n",
      "weighted avg       0.85      0.84      0.84       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_list))\n",
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "allied-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = random.sample(noun_phrases, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "entertaining-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples = []\n",
    "for sample in test_samples:\n",
    "    X_samples.append(embeddings[sample.replace(' ', '_')])\n",
    "sample_data = TestDataset(torch.FloatTensor(np.array(X_samples, dtype=np.float64)))\n",
    "sample_loader = DataLoader(dataset=sample_data, batch_size=1)\n",
    "\n",
    "extracted = {}\n",
    "not_extracted = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, X_batch in enumerate(sample_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        if y_pred_tag.cpu().numpy()[0][0] == 1:\n",
    "            extracted[test_samples[i]] = y_test_pred.item()\n",
    "        else:\n",
    "            not_extracted[test_samples[i]] = y_test_pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "crazy-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = set(['a', 'the', 'an'])\n",
    "filtered_out = {k: v for k, v in sorted(extracted.items(), key=lambda x: x[1], reverse=True) if k.split()[0] in articles}\n",
    "extracted = {k: v for k, v in sorted(extracted.items(), key=lambda x: x[1], reverse=True) if k.split()[0] not in articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cellular-warrior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the data': 0.9988104104995728,\n",
       " 'the parameters': 0.9969094395637512,\n",
       " 'the community': 0.968543529510498,\n",
       " 'a learning algorithm': 0.9325882792472839,\n",
       " 'a subclass': 0.9250819683074951,\n",
       " 'the diagnosis': 0.9113430976867676,\n",
       " 'the main challenges': 0.9031568169593811,\n",
       " 'the landscape': 0.8575482368469238,\n",
       " 'the formulation': 0.8460093140602112,\n",
       " 'the market': 0.8297961354255676,\n",
       " 'the general problem': 0.8228774070739746,\n",
       " 'the probability': 0.7972127199172974,\n",
       " 'a useful tool': 0.7856641411781311,\n",
       " 'the inverse': 0.7683600783348083,\n",
       " 'the biggest challenges': 0.7669466733932495,\n",
       " 'a time series': 0.7335924506187439,\n",
       " 'the sensitivity': 0.7116998434066772,\n",
       " 'a convex': 0.7075891494750977,\n",
       " 'the last decade': 0.5983960628509521,\n",
       " 'the methodology': 0.5199963450431824,\n",
       " 'the computer vision': 0.5022767782211304}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ordered-coaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 1.0,\n",
       " 'understanding': 1.0,\n",
       " 'distance': 1.0,\n",
       " 'resolution': 1.0,\n",
       " 'tree': 1.0,\n",
       " 'structure': 1.0,\n",
       " 'distributed': 0.9999998807907104,\n",
       " 'component': 0.9999997615814209,\n",
       " 'media': 0.9999996423721313,\n",
       " 'wide range': 0.9999996423721313,\n",
       " 'user': 0.9999995231628418,\n",
       " 'each': 0.9999994039535522,\n",
       " 'community': 0.9999960660934448,\n",
       " 'pixel': 0.9999880790710449,\n",
       " 'part': 0.999984622001648,\n",
       " 'variational': 0.9999821186065674,\n",
       " 'automated': 0.9998261332511902,\n",
       " 'expert': 0.9997286200523376,\n",
       " 'general': 0.9997221827507019,\n",
       " 'exact': 0.9994937181472778,\n",
       " 'average': 0.9993914365768433,\n",
       " 'python': 0.9989157915115356,\n",
       " 'component analysis': 0.9987931251525879,\n",
       " 'great potential': 0.9975887537002563,\n",
       " 'variation': 0.9974933862686157,\n",
       " 'number': 0.9959033131599426,\n",
       " 'neighbor': 0.9956662654876709,\n",
       " 'bandit': 0.995043158531189,\n",
       " 'attention mechanism': 0.9946053624153137,\n",
       " 'mcmc': 0.9940989017486572,\n",
       " 'many applications': 0.9938828945159912,\n",
       " 'model selection': 0.9895868301391602,\n",
       " 'volumes': 0.9894739985466003,\n",
       " 'messages': 0.9888246655464172,\n",
       " 'logistic regression': 0.9872719645500183,\n",
       " 'high probability': 0.9871174693107605,\n",
       " 'real valued': 0.9865390658378601,\n",
       " 'em algorithm': 0.9850525259971619,\n",
       " 'dependency': 0.9840812683105469,\n",
       " 'basis': 0.9840638637542725,\n",
       " 'registration': 0.9839890599250793,\n",
       " 'descent sgd': 0.983939528465271,\n",
       " 'lasso': 0.9830963611602783,\n",
       " 'this field': 0.982529878616333,\n",
       " 'hyperparameter': 0.9825127124786377,\n",
       " 'operations': 0.9816719889640808,\n",
       " 'adoption': 0.9814799427986145,\n",
       " 'degrees': 0.9808582663536072,\n",
       " 'risk': 0.9806085228919983,\n",
       " 'vehicle': 0.9785111546516418,\n",
       " 'sketch': 0.9754142165184021,\n",
       " 'off': 0.9735094308853149,\n",
       " 'clustering algorithm': 0.9703548550605774,\n",
       " 'cortex': 0.9690374135971069,\n",
       " 'psychology': 0.9663494229316711,\n",
       " 'fuzzy clustering': 0.963435173034668,\n",
       " 'multipliers admm': 0.9617733359336853,\n",
       " 'text processing': 0.9573328495025635,\n",
       " 'textit': 0.9553093910217285,\n",
       " 'kws': 0.9543274641036987,\n",
       " 'meta': 0.9537160396575928,\n",
       " 'retrieval': 0.9490957856178284,\n",
       " 'linear classification': 0.9485670328140259,\n",
       " 'optimism': 0.9464537501335144,\n",
       " 'race': 0.9462486505508423,\n",
       " 'image representation': 0.9428389668464661,\n",
       " 'inspiration': 0.9399016499519348,\n",
       " 'feature learning': 0.9378561973571777,\n",
       " 'analysis': 0.9365519881248474,\n",
       " 'recommendation systems': 0.9338603615760803,\n",
       " 'attentions': 0.9313188791275024,\n",
       " 'starts': 0.9286980032920837,\n",
       " 'early detection': 0.9242203235626221,\n",
       " 'security': 0.9129763841629028,\n",
       " 'id': 0.9104114770889282,\n",
       " 'increases': 0.9060751795768738,\n",
       " 'rectified linear unit relu': 0.90546715259552,\n",
       " 'fixed points': 0.9045340418815613,\n",
       " 'medical diagnosis': 0.9035214781761169,\n",
       " 'sublinear': 0.8990017771720886,\n",
       " 'quantitative analysis': 0.8945901989936829,\n",
       " 'sfa': 0.8937908411026001,\n",
       " 'multiplication': 0.8907246589660645,\n",
       " 'dialogue systems': 0.8735183477401733,\n",
       " 'room': 0.872449517250061,\n",
       " 'wang': 0.8585890531539917,\n",
       " 'pool': 0.8463473916053772,\n",
       " 'interest': 0.8416271209716797,\n",
       " 'semantic similarity': 0.8409446477890015,\n",
       " 'world': 0.8327234387397766,\n",
       " 'other types': 0.8282673954963684,\n",
       " 'divergences': 0.8152852058410645,\n",
       " 'multi label learning': 0.8136240243911743,\n",
       " 'significant challenges': 0.8081637024879456,\n",
       " 'mri': 0.805822491645813,\n",
       " '1 norm': 0.7989873290061951,\n",
       " 'ongoing research': 0.7975870966911316,\n",
       " 'image classification tasks': 0.7972469329833984,\n",
       " 'unitary': 0.7890315651893616,\n",
       " 'summaries': 0.7872132062911987,\n",
       " 'several problems': 0.7781811952590942,\n",
       " 'dynamic time': 0.7752612233161926,\n",
       " 'advantages and disadvantages': 0.7727953195571899,\n",
       " 'variational auto encoders': 0.7682176828384399,\n",
       " 'partitioning': 0.7625712156295776,\n",
       " 'metadata': 0.7591731548309326,\n",
       " 'correspondence': 0.7527586221694946,\n",
       " 'hyperplane': 0.750770628452301,\n",
       " 'bangla alphabet': 0.7419164180755615,\n",
       " 'human activities': 0.7379641532897949,\n",
       " 'practical applications': 0.7292615175247192,\n",
       " 'opinion mining': 0.7285813093185425,\n",
       " 'increasing interest': 0.7217923998832703,\n",
       " 'data centers': 0.7216075658798218,\n",
       " 'mobile devices': 0.712183952331543,\n",
       " 'fisher': 0.7015330195426941,\n",
       " 'insight': 0.6928440928459167,\n",
       " 'machine learning and artificial intelligence': 0.6812721490859985,\n",
       " 'approximations': 0.6731008291244507,\n",
       " 'principle': 0.6708823442459106,\n",
       " 'many nlp applications': 0.66688072681427,\n",
       " 'recent times': 0.6662987470626831,\n",
       " 'noisy images': 0.6555070877075195,\n",
       " 'their applicability': 0.6547412276268005,\n",
       " 'statistical inference': 0.6505030989646912,\n",
       " 'debates': 0.6429538130760193,\n",
       " 'popularity': 0.6423330307006836,\n",
       " 'long horizons': 0.6408289074897766,\n",
       " 'random fields': 0.6364974975585938,\n",
       " 'fourier': 0.631566047668457,\n",
       " 'businesses': 0.6277649998664856,\n",
       " 'substitute': 0.6176574230194092,\n",
       " 'low rank': 0.6174928545951843,\n",
       " 'disease diagnosis': 0.6120761036872864,\n",
       " 'subject': 0.6094675064086914,\n",
       " 'logs': 0.6079263687133789,\n",
       " 'latent structure': 0.606102705001831,\n",
       " 'system identification': 0.6032726168632507,\n",
       " 'components': 0.5968523621559143,\n",
       " 'backprop': 0.5620095133781433,\n",
       " 'moment': 0.5496324300765991,\n",
       " 'attacks and defenses': 0.5482754111289978,\n",
       " 'toolkits': 0.5398930907249451,\n",
       " 'textbf': 0.5398830771446228,\n",
       " 'vote': 0.5370462536811829,\n",
       " 'concern': 0.5366808772087097,\n",
       " 'many practical applications': 0.5334904193878174,\n",
       " 'web': 0.5314236283302307,\n",
       " 'templates': 0.529999315738678,\n",
       " 'translation': 0.5246866941452026,\n",
       " 'lower': 0.5214546918869019,\n",
       " 'l2 regularization': 0.5214277505874634,\n",
       " 'point processes': 0.5166525840759277,\n",
       " 'organism': 0.5142568945884705,\n",
       " 'sparseness': 0.5056676268577576,\n",
       " 'structure learning': 0.5000757575035095}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dominant-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_extracted = {k: v for k, v in sorted(not_extracted.items(), key=lambda x: x[1], reverse=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "mature-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': 2.2008531175288226e-07,\n",
       " 'classification': 3.0414901175390696e-07,\n",
       " 'improvements': 4.977708840669948e-07,\n",
       " 'existing': 1.5112763094293769e-06,\n",
       " 'games': 4.5229476199892815e-06,\n",
       " 'four': 6.298792868619785e-06,\n",
       " 'the art approaches': 8.325323506142013e-06,\n",
       " 'types': 1.1033292139472906e-05,\n",
       " 'relations': 1.2441348189895507e-05,\n",
       " 'metrics': 1.4485356587101705e-05,\n",
       " 'english': 1.4825439393462148e-05,\n",
       " 'based approaches': 1.911602339532692e-05,\n",
       " 'superiority': 2.152036176994443e-05,\n",
       " 'tests': 2.5420762540306896e-05,\n",
       " 'deep architectures': 2.8696356821455993e-05,\n",
       " 'works': 3.390853089513257e-05,\n",
       " 'combinations': 3.702683170558885e-05,\n",
       " 'the best': 4.63464020867832e-05,\n",
       " 'the experimental results': 5.951167258899659e-05,\n",
       " 'a novel': 7.513133459724486e-05,\n",
       " 'the spatial': 9.647354454500601e-05,\n",
       " 'sentiment': 0.00012739021622110158,\n",
       " 'dependencies': 0.00014671571261715144,\n",
       " 'neurons': 0.00014859868679195642,\n",
       " 'situations': 0.00015146943042054772,\n",
       " 'goals': 0.00015906502085272223,\n",
       " 'experience': 0.00016582407988607883,\n",
       " 'image datasets': 0.00016783956380095333,\n",
       " 'objects': 0.0001711108343442902,\n",
       " 'natural images': 0.00020068282901775092,\n",
       " 'changes': 0.0002523668808862567,\n",
       " 'products': 0.00027806806610897183,\n",
       " 'relation': 0.0002988626074511558,\n",
       " 'scenes': 0.00031395029509440064,\n",
       " 'the latter': 0.00031715453951619565,\n",
       " 'analyses': 0.0003433386445976794,\n",
       " 'the results': 0.0004559223889373243,\n",
       " 'segmentation': 0.0004793705593328923,\n",
       " 'others': 0.0005279447068460286,\n",
       " 'mil': 0.0005334868328645825,\n",
       " 'concepts': 0.0005391755839809775,\n",
       " 'rankings': 0.0005498144892044365,\n",
       " 'targets': 0.0005642007454298437,\n",
       " 'imagenet': 0.0006714682094752789,\n",
       " 'classes': 0.0006764995050616562,\n",
       " 'guarantees': 0.0006880485452711582,\n",
       " 'mlp': 0.0007760777953080833,\n",
       " 'go': 0.0008272258564829826,\n",
       " 'molecules': 0.0010451223934069276,\n",
       " 'issues': 0.0010570663725957274,\n",
       " 'proposed models': 0.0011847054120153189,\n",
       " 'recognition systems': 0.0012332034530118108,\n",
       " 'meanings': 0.0012725531123578548,\n",
       " 'a deep neural network': 0.0012926777126267552,\n",
       " 'this kind': 0.0013047700049355626,\n",
       " 'reviews': 0.0013419028837233782,\n",
       " 'these networks': 0.0014284634962677956,\n",
       " 'formulas': 0.001430186559446156,\n",
       " 'treatments': 0.0014340762281790376,\n",
       " 'the majority': 0.0014789467677474022,\n",
       " 'decision making': 0.0014870259910821915,\n",
       " 'animals': 0.0015171465929597616,\n",
       " 'the inputs': 0.0015890744980424643,\n",
       " 'lower bounds': 0.0016334840329363942,\n",
       " 'facts': 0.001647442695684731,\n",
       " 'theorems': 0.0017677608411759138,\n",
       " 'pipelines': 0.0018730743322521448,\n",
       " 'an improvement': 0.0019197819055989385,\n",
       " 'two models': 0.0019708964973688126,\n",
       " 'causal models': 0.00199183844961226,\n",
       " 'a family': 0.0021366754081100225,\n",
       " 'boltzmann machines': 0.0022292465437203646,\n",
       " 'the art techniques': 0.0022414897102862597,\n",
       " 'things': 0.0022728852927684784,\n",
       " 'the arts': 0.0022956719622015953,\n",
       " 'the remaining': 0.002377782016992569,\n",
       " 'the connections': 0.0025376302655786276,\n",
       " 'a combination': 0.0025706675369292498,\n",
       " 'matches': 0.002594469115138054,\n",
       " 'quantization': 0.0026449488941580057,\n",
       " 'different modalities': 0.0026712296530604362,\n",
       " 'controllers': 0.0027889765333384275,\n",
       " 'representations': 0.002788981655612588,\n",
       " 'clustering methods': 0.0028144349344074726,\n",
       " 'desirable properties': 0.002858547493815422,\n",
       " 'large numbers': 0.0029358058236539364,\n",
       " 'character level': 0.002980839926749468,\n",
       " 'cameras': 0.00324557488784194,\n",
       " 'data samples': 0.003269277745857835,\n",
       " 'encouraging results': 0.003273509908467531,\n",
       " 'appearance': 0.0034543341025710106,\n",
       " 'services': 0.003510265378281474,\n",
       " 'phoneme recognition': 0.003624729113653302,\n",
       " 'the similarity': 0.0037644514814019203,\n",
       " 'a linear combination': 0.003766096895560622,\n",
       " 'each individual': 0.004184742923825979,\n",
       " 'google cloud': 0.0042302776128053665,\n",
       " 'judgments': 0.004285956732928753,\n",
       " 'bn': 0.004319119267165661,\n",
       " 'various tasks': 0.004335275385528803,\n",
       " '100': 0.004343326203525066,\n",
       " 'data augmentation': 0.0045362478122115135,\n",
       " 'the wild': 0.004604818299412727,\n",
       " 'different algorithms': 0.004846858326345682,\n",
       " 'the distributions': 0.004850438330322504,\n",
       " 'engineers': 0.00487033324316144,\n",
       " 'a new architecture': 0.005067164544016123,\n",
       " 'the dialogue': 0.005084610544145107,\n",
       " 'markov decision': 0.0052510942332446575,\n",
       " 'the help': 0.005269928369671106,\n",
       " 'the applicability': 0.005305102095007896,\n",
       " 'change': 0.005646205972880125,\n",
       " 'past observations': 0.005725684575736523,\n",
       " 'a unified framework': 0.005742440931499004,\n",
       " 'publicly available datasets': 0.005818221718072891,\n",
       " 'that deep learning': 0.005819286219775677,\n",
       " 'averaging': 0.005876676645129919,\n",
       " 'the same': 0.00594767089933157,\n",
       " 'proteins': 0.006241140887141228,\n",
       " 'learning agents': 0.00631227670237422,\n",
       " 'feature representations': 0.00635940209031105,\n",
       " 'almost all': 0.006404152140021324,\n",
       " 'causal inference': 0.0066624111495912075,\n",
       " 'voice search': 0.006889840122312307,\n",
       " 'standard benchmarks': 0.0071205319836735725,\n",
       " 'programming asp': 0.007207205053418875,\n",
       " 'this model': 0.007338938303291798,\n",
       " 'viewpoints': 0.007447907701134682,\n",
       " 'a recently proposed': 0.00758407823741436,\n",
       " 'vqa models': 0.007835237309336662,\n",
       " 'millions of parameters': 0.007842431776225567,\n",
       " 'many cases': 0.007954864762723446,\n",
       " 'dictionary atoms': 0.008176219649612904,\n",
       " 'pomdps': 0.008177624084055424,\n",
       " 'data space': 0.008190078660845757,\n",
       " 'discriminative features': 0.008242507465183735,\n",
       " 'variational approximations': 0.008370568044483662,\n",
       " 'bayesian methods': 0.008470993489027023,\n",
       " 'requests': 0.009118383750319481,\n",
       " 'a novel approach': 0.009156725369393826,\n",
       " 'cost functions': 0.009206956252455711,\n",
       " 'permutations': 0.009230582974851131,\n",
       " 'linguistic knowledge': 0.009249965660274029,\n",
       " 'sequence modeling': 0.009409237653017044,\n",
       " 'a principled manner': 0.009451232850551605,\n",
       " 'semantic concepts': 0.009613609872758389,\n",
       " 'a knowledge base': 0.00969128217548132,\n",
       " 'the shift': 0.009714512154459953,\n",
       " 'keyphrases': 0.009785021655261517,\n",
       " 'semantic parts': 0.00980942789465189,\n",
       " 'a generator': 0.00990332756191492,\n",
       " 'target images': 0.010028604418039322,\n",
       " 'accurate predictions': 0.010091248899698257,\n",
       " 'genomic data': 0.010217451490461826,\n",
       " 'audio': 0.010244268923997879,\n",
       " 'the natural language': 0.010429681278765202,\n",
       " 'trials': 0.010442405939102173,\n",
       " 'individual labels': 0.010545562021434307,\n",
       " 'each category': 0.0105965631082654,\n",
       " 'a graphical model': 0.01070854440331459,\n",
       " 'uncertainty information': 0.010991762392222881,\n",
       " 'training generative models': 0.011019716039299965,\n",
       " 'smaller models': 0.01105201430618763,\n",
       " 'their work': 0.011316901072859764,\n",
       " 'latent codes': 0.011322546750307083,\n",
       " 'probability density': 0.01140712108463049,\n",
       " 'some others': 0.011560100130736828,\n",
       " 'infogan': 0.011680331081151962,\n",
       " 'a layer': 0.011691125109791756,\n",
       " 'a knowledge graph': 0.01173838134855032,\n",
       " 'special attention': 0.011768145486712456,\n",
       " 'a causal graph': 0.011956421658396721,\n",
       " 'a new policy': 0.011979291215538979,\n",
       " 'the type': 0.012037340551614761,\n",
       " 'nested dropout': 0.012070627883076668,\n",
       " 'forms': 0.012131250463426113,\n",
       " 'multiple sources': 0.012302826158702374,\n",
       " 'natural image patches': 0.01236285362392664,\n",
       " 'rectifier networks': 0.012390680611133575,\n",
       " 'a novel formulation': 0.012459160760045052,\n",
       " 'a feature vector': 0.012492116540670395,\n",
       " 'deep representations': 0.01250259205698967,\n",
       " 'a curriculum': 0.012716911733150482,\n",
       " 'addition': 0.012867211364209652,\n",
       " 'video games': 0.012936110608279705,\n",
       " 'prior works': 0.013087810017168522,\n",
       " 'repetitions': 0.013144928961992264,\n",
       " 'demonstrations': 0.01323703397065401,\n",
       " 'item ratings': 0.013324219733476639,\n",
       " 'approximate': 0.013423239812254906,\n",
       " 'a novel end': 0.013440200127661228,\n",
       " 'the large number': 0.013441331684589386,\n",
       " 'variational methods': 0.013710147701203823,\n",
       " 'a social network': 0.013755717314779758,\n",
       " 'policy parameters': 0.013804709538817406,\n",
       " 'their structure': 0.013992280699312687,\n",
       " 'graph kernels': 0.014094497077167034,\n",
       " 'their labels': 0.01409754529595375,\n",
       " 'memories': 0.014101642183959484,\n",
       " 'a translation': 0.01431167684495449,\n",
       " 'wikipedia': 0.01431171502918005,\n",
       " 'the size of the network': 0.014328213408589363,\n",
       " 'a convex function': 0.014345293864607811,\n",
       " 'that language': 0.014418712817132473,\n",
       " 'the limits': 0.01448072399944067,\n",
       " 'update rules': 0.014608502388000488,\n",
       " 'binary variables': 0.014634264633059502,\n",
       " 'a real': 0.014747127890586853,\n",
       " 'a word': 0.014775021001696587,\n",
       " 'k mle': 0.014790771529078484,\n",
       " '2010': 0.014807213097810745,\n",
       " 'the measurements': 0.01485169306397438,\n",
       " 'deeplift': 0.015010121278464794,\n",
       " 'the key': 0.01507642399519682,\n",
       " 'melodies': 0.01514942105859518,\n",
       " 'conditional dependencies': 0.01530618965625763,\n",
       " 'leaf nodes': 0.015399226918816566,\n",
       " 'sequence modeling tasks': 0.01561729609966278,\n",
       " 'labeling tasks': 0.015688622370362282,\n",
       " 'the responses': 0.015760622918605804,\n",
       " 'different regions': 0.015791956335306168,\n",
       " 'tractography': 0.015811413526535034,\n",
       " 'label information': 0.016094006597995758,\n",
       " 'forgeries': 0.016182521358132362,\n",
       " 'the experts': 0.016568763181567192,\n",
       " 'two steps': 0.0165813397616148,\n",
       " 'function evaluations': 0.01659339666366577,\n",
       " 'face images': 0.016858959570527077,\n",
       " 'the system dynamics': 0.016950123012065887,\n",
       " 'the classification problem': 0.016973618417978287,\n",
       " 'different channels': 0.01699747145175934,\n",
       " 'an edge': 0.0170428566634655,\n",
       " 'two variants': 0.017120450735092163,\n",
       " 'visual scene': 0.017189674079418182,\n",
       " 'pair wise comparisons': 0.01727566309273243,\n",
       " 'multi instance': 0.01743217557668686,\n",
       " 'object detection': 0.01748383417725563,\n",
       " 'representative features': 0.01777779310941696,\n",
       " 'support vector regression': 0.017790518701076508,\n",
       " 'learning classifier': 0.01782233454287052,\n",
       " 'individual layers': 0.017897814512252808,\n",
       " 'pulmonary nodules': 0.017905717715620995,\n",
       " 'this question': 0.01806795783340931,\n",
       " 'saliency prediction': 0.018177319318056107,\n",
       " 'gmm': 0.018295789137482643,\n",
       " 'a finite': 0.018394920974969864,\n",
       " 'similarity measures': 0.01841770112514496,\n",
       " 'new evidence': 0.01846538484096527,\n",
       " 'generalization performance': 0.01865990459918976,\n",
       " 'its weights': 0.018667947500944138,\n",
       " 'a deep model': 0.01867339387536049,\n",
       " 'generalization properties': 0.01877760700881481,\n",
       " 'dirichlet process mixture models': 0.018969986587762833,\n",
       " 'speaker recognition': 0.01917685940861702,\n",
       " 'a special type': 0.019236786291003227,\n",
       " 'pose': 0.01924366131424904,\n",
       " 'static images': 0.019266050308942795,\n",
       " 'the hypothesis space': 0.019509244710206985,\n",
       " 'word embeddings': 0.019601967185735703,\n",
       " 'stationary points': 0.019689451903104782,\n",
       " 'permutation testing': 0.019758161157369614,\n",
       " 'the source': 0.01981852948665619,\n",
       " 'the real world': 0.019920744001865387,\n",
       " 'the process': 0.02011055126786232,\n",
       " 'its theoretical properties': 0.02026810310781002,\n",
       " 'continuous attributes': 0.020304888486862183,\n",
       " 'the moments': 0.020321443676948547,\n",
       " 'two properties': 0.020396187901496887,\n",
       " 'dog': 0.020404720678925514,\n",
       " 'the observed data': 0.020411722362041473,\n",
       " 'explicit feedback': 0.020548446103930473,\n",
       " 'discriminative learning': 0.020616309717297554,\n",
       " 'the space': 0.02071758732199669,\n",
       " 'external memory': 0.020726721733808517,\n",
       " 'visual scenes': 0.02073766104876995,\n",
       " 'boolean functions': 0.02073868177831173,\n",
       " 'bi': 0.020992597565054893,\n",
       " 'the inverse problem': 0.02101503126323223,\n",
       " 'the association': 0.021134838461875916,\n",
       " 'weeks': 0.021140120923519135,\n",
       " 'the entire image': 0.021254656836390495,\n",
       " 'combinatorial optimization problems': 0.021297920495271683,\n",
       " 'a few examples': 0.021378053352236748,\n",
       " 'the second order statistics': 0.02140233851969242,\n",
       " 'count': 0.02141622081398964,\n",
       " 'behavioral data': 0.021568063646554947,\n",
       " 'neural network parameters': 0.021573759615421295,\n",
       " 'the heterogeneity': 0.021601546555757523,\n",
       " 'the ambient': 0.02164938859641552,\n",
       " 'stochastic processes': 0.021653782576322556,\n",
       " 'input features': 0.021662354469299316,\n",
       " 'the membership': 0.02172321453690529,\n",
       " 'the learned representations': 0.021965255960822105,\n",
       " 'convex surrogates': 0.021998994052410126,\n",
       " 'the classifier': 0.022011540830135345,\n",
       " 'sparse signal': 0.02224210649728775,\n",
       " 'an effective algorithm': 0.022330785170197487,\n",
       " 'a relaxation': 0.02241070196032524,\n",
       " 'the latent code': 0.022439870983362198,\n",
       " 'label correlations': 0.022539209574460983,\n",
       " 'sparse representations': 0.02291860617697239,\n",
       " 'marginal distributions': 0.023137427866458893,\n",
       " 'someone': 0.023182503879070282,\n",
       " 'salient regions': 0.023237470537424088,\n",
       " 'training distribution': 0.023293154314160347,\n",
       " 'the generalizability': 0.02329636737704277,\n",
       " 'a proxy': 0.02329654060304165,\n",
       " 'inequalities': 0.02347414754331112,\n",
       " 'a joint distribution': 0.023685794323682785,\n",
       " 'artificial systems': 0.02374851144850254,\n",
       " 'human brain': 0.023869751021265984,\n",
       " 'the target language': 0.023990483954548836,\n",
       " 'the classes': 0.0240071602165699,\n",
       " 'the covariates': 0.024018708616495132,\n",
       " 'the input layer': 0.0240886639803648,\n",
       " 'search engines': 0.02409096248447895,\n",
       " 'a limited amount': 0.02421029657125473,\n",
       " 'the quality': 0.024290502071380615,\n",
       " 'rl tasks': 0.024440990760922432,\n",
       " 'these items': 0.02444521337747574,\n",
       " 'most approaches': 0.024475544691085815,\n",
       " 'fmri datasets': 0.024484192952513695,\n",
       " 'causal directions': 0.024526355788111687,\n",
       " 'scratch': 0.02470647171139717,\n",
       " 'the transition function': 0.024731021374464035,\n",
       " 'a large pool': 0.024768270552158356,\n",
       " 'scarcity': 0.025166887789964676,\n",
       " 'digits': 0.0252060666680336,\n",
       " 'the training dataset': 0.025251289829611778,\n",
       " 'computing resources': 0.02536330185830593,\n",
       " 'a distributed representation': 0.025481117889285088,\n",
       " 'this knowledge': 0.0256811510771513,\n",
       " 'photographic images': 0.025938689708709717,\n",
       " 'two dimensions': 0.026022713631391525,\n",
       " 'a learning task': 0.02612699568271637,\n",
       " 'i.i.d. samples': 0.026275264099240303,\n",
       " 'a multi layer': 0.026379868388175964,\n",
       " 'interpretable machine': 0.026446891948580742,\n",
       " 'a virtual environment': 0.026631342247128487,\n",
       " 'non convex optimization': 0.02669151872396469,\n",
       " 'unlabeled images': 0.026727858930826187,\n",
       " 'relevant objects': 0.026786062866449356,\n",
       " 'an fpga': 0.026888543739914894,\n",
       " 'human attention': 0.027281632646918297,\n",
       " 'a given dataset': 0.02737932652235031,\n",
       " 'the bootstrap': 0.027515197172760963,\n",
       " 'calls': 0.027746565639972687,\n",
       " 'performance criteria': 0.02775443159043789,\n",
       " 'a prior distribution': 0.027943510562181473,\n",
       " 'complex behaviors': 0.0280285831540823,\n",
       " 'prediction time': 0.02817462757229805,\n",
       " 'two layers': 0.028244340792298317,\n",
       " 'the context': 0.028361031785607338,\n",
       " 'new tools': 0.028614385053515434,\n",
       " 'important implications': 0.028682252392172813,\n",
       " 'a human operator': 0.028732996433973312,\n",
       " 'meta mining': 0.02877594158053398,\n",
       " 'mrfs': 0.02879377268254757,\n",
       " 'discrete objects': 0.028867438435554504,\n",
       " 'the likelihood': 0.028959790244698524,\n",
       " 'the proposed method': 0.02896050736308098,\n",
       " 'the nearest neighbor rule': 0.029061099514365196,\n",
       " 'two samples': 0.029249878600239754,\n",
       " 'autonomy': 0.02939039282500744,\n",
       " 'weakly supervised classification': 0.02975337579846382,\n",
       " 'model performance': 0.03030523657798767,\n",
       " 'kernel learning methods': 0.030403606593608856,\n",
       " 'the capture': 0.0305523332208395,\n",
       " 'graph embedding': 0.031135672703385353,\n",
       " 'words bow': 0.03115180879831314,\n",
       " 'high cost': 0.031163297593593597,\n",
       " 'the ideas': 0.03133006766438484,\n",
       " 'neural reasoner': 0.031898412853479385,\n",
       " 'rademacher complexity bounds': 0.03198002278804779,\n",
       " 'the dependencies': 0.0321168527007103,\n",
       " 'xx': 0.03249668702483177,\n",
       " '80': 0.03255317360162735,\n",
       " 'the sense': 0.03257794678211212,\n",
       " 'this issue': 0.03267354145646095,\n",
       " 'special focus': 0.03271827846765518,\n",
       " 'specific tasks': 0.032829709351062775,\n",
       " 'newton s': 0.03289208561182022,\n",
       " 'policy gradient': 0.03297242149710655,\n",
       " 'youtube videos': 0.0331275574862957,\n",
       " 'the generative ability': 0.03318087011575699,\n",
       " 'gibbs sampling': 0.03329942747950554,\n",
       " 'wda': 0.03354881331324577,\n",
       " 'statistical physics': 0.03355148062109947,\n",
       " 'riemannian geometry': 0.03355256840586662,\n",
       " 'semantic annotations': 0.03356536477804184,\n",
       " 'a new variant': 0.03359119966626167,\n",
       " 'future events': 0.03362663462758064,\n",
       " 'regression problems': 0.033670078963041306,\n",
       " 'a single input image': 0.034050118178129196,\n",
       " 'a weighted graph': 0.034053049981594086,\n",
       " 'pragmatics': 0.03406234458088875,\n",
       " 'a given query': 0.034159693866968155,\n",
       " 'the boundaries': 0.03419863060116768,\n",
       " 'an adversary': 0.034296631813049316,\n",
       " 'user feedback': 0.03429679572582245,\n",
       " 'dlms': 0.03431509807705879,\n",
       " 'the hierarchical dirichlet process': 0.03437458351254463,\n",
       " 'generative networks': 0.0343841128051281,\n",
       " 'belief networks': 0.0347151905298233,\n",
       " 'such processes': 0.0347713902592659,\n",
       " 'eeg signals': 0.03481234237551689,\n",
       " 'graph construction': 0.03481297567486763,\n",
       " 'a supervised learning': 0.03487245365977287,\n",
       " 'a denoising': 0.034900419414043427,\n",
       " 'the latent signal': 0.03506535664200783,\n",
       " 'a reduction': 0.035429611802101135,\n",
       " 'a new kind': 0.03548428416252136,\n",
       " 'one to one': 0.035608768463134766,\n",
       " 'bayesian approach': 0.035637397319078445,\n",
       " 'graph structures': 0.03608592599630356,\n",
       " 'a correspondence': 0.03632654622197151,\n",
       " 'the extraction': 0.036979932337999344,\n",
       " 'bits': 0.03708624467253685,\n",
       " 'the activity': 0.03720783069729805,\n",
       " 'exposure': 0.03724364936351776,\n",
       " 'variational autoencoder vae': 0.037327900528907776,\n",
       " 'the output sequence': 0.03739771991968155,\n",
       " 'non gaussian noise': 0.037687260657548904,\n",
       " 'synapses': 0.03780464828014374,\n",
       " 'possible classes': 0.0378083810210228,\n",
       " 'neurons in the network': 0.03783499076962471,\n",
       " 'ways': 0.03788936510682106,\n",
       " 'each arm': 0.03792519122362137,\n",
       " 'the trajectories': 0.03849797695875168,\n",
       " 'novel applications': 0.038531895726919174,\n",
       " 'an entropy': 0.03870999813079834,\n",
       " 'the samples': 0.038789909332990646,\n",
       " 'representation learning methods': 0.03880167752504349,\n",
       " 'the set': 0.03898058831691742,\n",
       " 'open questions': 0.03922540321946144,\n",
       " '5': 0.039449386298656464,\n",
       " 'small datasets': 0.039831388741731644,\n",
       " 'care': 0.040311168879270554,\n",
       " 'the target policy': 0.040548864752054214,\n",
       " '2d images': 0.04071880877017975,\n",
       " 'its core': 0.04136824607849121,\n",
       " 'a segmentation': 0.04174468666315079,\n",
       " 'wanderer': 0.042221393436193466,\n",
       " 'a hidden markov model': 0.04241235926747322,\n",
       " 'the columns': 0.042523592710494995,\n",
       " 'the estimation': 0.04296136647462845,\n",
       " 'short': 0.0438239723443985,\n",
       " 'this phenomenon': 0.044179175049066544,\n",
       " 'tuning parameter': 0.04421702399849892,\n",
       " 'biological neural networks': 0.04438196122646332,\n",
       " 'linear regions': 0.044509898871183395,\n",
       " 'super convergence': 0.04477495700120926,\n",
       " 'spectral algorithms': 0.04488556459546089,\n",
       " 'secondary structure prediction': 0.04496605321764946,\n",
       " 'compromise': 0.04499463737010956,\n",
       " 'the objects': 0.045153483748435974,\n",
       " 'a multilayer perceptron': 0.04600398987531662,\n",
       " 'random perturbations': 0.046417541801929474,\n",
       " 'klsh': 0.04663309082388878,\n",
       " 'video generation': 0.046718843281269073,\n",
       " 'noise injection': 0.046895358711481094,\n",
       " 'a kind': 0.04692000150680542,\n",
       " 'noisy measurements': 0.04722200706601143,\n",
       " 'connectionist temporal classification ctc': 0.047239046543836594,\n",
       " 'exponential dependence': 0.04729326814413071,\n",
       " 'indirect supervision': 0.047450803220272064,\n",
       " 'constant time': 0.04756404086947441,\n",
       " 'certainty': 0.04758821800351143,\n",
       " 'the equivalence': 0.04799266532063484,\n",
       " 'coins': 0.04817315191030502,\n",
       " 'only a small number': 0.04819875955581665,\n",
       " 'a query': 0.04842918738722801,\n",
       " 'the total': 0.04844275116920471,\n",
       " 'related problems': 0.048473890870809555,\n",
       " 'a number of tasks': 0.048549652099609375,\n",
       " 'a particular task': 0.04861815646290779,\n",
       " 'a distributed system': 0.04885895550251007,\n",
       " 'the label distribution': 0.048928603529930115,\n",
       " 'dynamic declaration': 0.0492536686360836,\n",
       " 'sensor noise': 0.049335721880197525,\n",
       " 'multispectral images': 0.04951971396803856,\n",
       " 'learner model': 0.04973917827010155,\n",
       " 'low dimensional features': 0.05003820359706879,\n",
       " 'computational savings': 0.050118569284677505,\n",
       " 'several improvements': 0.05062852054834366,\n",
       " 'each point': 0.05065356567502022,\n",
       " 'artificial neural network ann': 0.05072112753987312,\n",
       " 'statistical analysis': 0.051710184663534164,\n",
       " 'object identity': 0.051909588277339935,\n",
       " 'a fixed number': 0.05245843902230263,\n",
       " 'at most k': 0.052556078881025314,\n",
       " 'gradient optimization': 0.05299433320760727,\n",
       " 'bitwise operations': 0.05303572490811348,\n",
       " 'its complexity': 0.05321699008345604,\n",
       " 'data sources': 0.053298309445381165,\n",
       " 'memorization': 0.05348677933216095,\n",
       " 'the learning rate': 0.05364537611603737,\n",
       " 'sga': 0.05408105626702309,\n",
       " 'rainfall': 0.054863788187503815,\n",
       " 'research papers': 0.054879337549209595,\n",
       " 'the hypotheses': 0.05515096336603165,\n",
       " 'changing environments': 0.05524389073252678,\n",
       " 'a new perspective': 0.05524535849690437,\n",
       " 'rewards': 0.05604097619652748,\n",
       " 'expert systems': 0.056147824972867966,\n",
       " 'a wide class': 0.05620082467794418,\n",
       " 'a series': 0.05633657053112984,\n",
       " 'kernel machines': 0.05688955634832382,\n",
       " 'the false positive rate': 0.057157304137945175,\n",
       " 'the mean': 0.05722936615347862,\n",
       " 'translation quality': 0.057265132665634155,\n",
       " 'human visual attention': 0.057277388870716095,\n",
       " 'a shift': 0.05752791464328766,\n",
       " 'optimize': 0.05764206871390343,\n",
       " 'other problems': 0.05775301530957222,\n",
       " 'descent algorithm': 0.058257460594177246,\n",
       " 'spam': 0.05857030674815178,\n",
       " 'neural representations': 0.058752961456775665,\n",
       " 'behaviour': 0.05884367972612381,\n",
       " 'the points': 0.05889788269996643,\n",
       " 'gait': 0.05936024710536003,\n",
       " 'the momentum': 0.060380954295396805,\n",
       " 'the redundancy': 0.06047336757183075,\n",
       " 'physical properties': 0.06078105419874191,\n",
       " 'the past decades': 0.060806754976511,\n",
       " 'weakly labeled data': 0.06113520637154579,\n",
       " 'predictive accuracy': 0.06131862848997116,\n",
       " 'a machine learning model': 0.0614282488822937,\n",
       " 'domain experts': 0.06181927025318146,\n",
       " 'variable selection': 0.06269613653421402,\n",
       " 'abstract features': 0.06285837292671204,\n",
       " 'a significant amount': 0.06295322626829147,\n",
       " 'each data point': 0.06308399885892868,\n",
       " 'computational intelligence': 0.06317222118377686,\n",
       " 'the recognition': 0.06321703642606735,\n",
       " 'successive generations': 0.06415262073278427,\n",
       " 'competition': 0.06425996124744415,\n",
       " 'textual content': 0.06470083445310593,\n",
       " 'regression and classification tasks': 0.06537976115942001,\n",
       " 'question generation': 0.06574281305074692,\n",
       " 'both of them': 0.06585057079792023,\n",
       " 'its capability': 0.06634843349456787,\n",
       " 'the computer vision community': 0.0665668472647667,\n",
       " 'many types': 0.0677335113286972,\n",
       " 'a predictor': 0.06794949620962143,\n",
       " 'rapid development': 0.068105548620224,\n",
       " 'the test data': 0.06860902160406113,\n",
       " 'the parents': 0.0702306255698204,\n",
       " 'key factors': 0.07034602761268616,\n",
       " 'brain images': 0.07034860551357269,\n",
       " 'dempster shafer clustering': 0.07083021104335785,\n",
       " 'multiple modes': 0.07095221430063248,\n",
       " 'a unifying framework': 0.07099266350269318,\n",
       " 'a new task': 0.07120732963085175,\n",
       " 'the privacy': 0.07330761104822159,\n",
       " 'peer': 0.07380915433168411,\n",
       " 'visual information': 0.07468148320913315,\n",
       " 'the neighbors': 0.07484382390975952,\n",
       " 'vae': 0.07566826045513153,\n",
       " 'their data': 0.07645611464977264,\n",
       " 'unique challenges': 0.07652942091226578,\n",
       " 'probabilities': 0.07665549963712692,\n",
       " 'human raters': 0.07767846435308456,\n",
       " 'the contents': 0.07769300043582916,\n",
       " 'cognitive processes': 0.07904554903507233,\n",
       " 'euclidean space': 0.07964686304330826,\n",
       " 'the performance of the system': 0.0797002762556076,\n",
       " 'little work': 0.08012708276510239,\n",
       " 'value functions': 0.08019305765628815,\n",
       " 'the weighted': 0.08026450872421265,\n",
       " 'embedding methods': 0.0814550518989563,\n",
       " 'compositional': 0.0814763680100441,\n",
       " 'visual turing test': 0.08203000575304031,\n",
       " 'generalisation': 0.08236362040042877,\n",
       " 'right': 0.08348967134952545,\n",
       " 'sampling algorithms': 0.08623497933149338,\n",
       " 'most cases': 0.08664616197347641,\n",
       " 'more complex ones': 0.08671639114618301,\n",
       " 'human annotators': 0.08688230067491531,\n",
       " 'larger': 0.08741521835327148,\n",
       " 'the region': 0.08958600461483002,\n",
       " 'monotonicity': 0.0900404304265976,\n",
       " 'the representational power': 0.09006993472576141,\n",
       " 'automatic speech recognition asr': 0.09139085561037064,\n",
       " 'gatys': 0.0914296880364418,\n",
       " 'innovation': 0.09156006574630737,\n",
       " 'difficult tasks': 0.09192503243684769,\n",
       " 'a special case': 0.09332413971424103,\n",
       " 'cars': 0.09367132186889648,\n",
       " 'tags': 0.09394820034503937,\n",
       " 'convergence properties': 0.09519290924072266,\n",
       " 'training data': 0.09530254453420639,\n",
       " 'their variants': 0.09682544320821762,\n",
       " 'the paradigm': 0.09686753153800964,\n",
       " 'the gradient': 0.09705387055873871,\n",
       " 'a significant impact': 0.09708166122436523,\n",
       " 'visual recognition': 0.09798002988100052,\n",
       " 'jobs': 0.09979888796806335,\n",
       " 'balls': 0.10047975927591324,\n",
       " 'riemannian manifolds': 0.10160364955663681,\n",
       " 'much interest': 0.1021757423877716,\n",
       " 'such algorithms': 0.10345082730054855,\n",
       " 'edges': 0.10454417765140533,\n",
       " 'spectral graph': 0.10496065020561218,\n",
       " 'non convex optimization problem': 0.10581033676862717,\n",
       " 'the unsupervised learning': 0.10611145198345184,\n",
       " 'the research': 0.10646176338195801,\n",
       " 'plda': 0.11012899875640869,\n",
       " 'classification systems': 0.11019590497016907,\n",
       " 'prediction problems': 0.11039744317531586,\n",
       " 'the costs': 0.11066212505102158,\n",
       " 'dynamic environments': 0.11078238487243652,\n",
       " 'object recognition tasks': 0.11088506877422333,\n",
       " 'expert advice': 0.11226966232061386,\n",
       " 'its implementation': 0.11235904693603516,\n",
       " 'a regularizer': 0.1129513531923294,\n",
       " 'a high dimensional': 0.11353101581335068,\n",
       " 'great attention': 0.11400055885314941,\n",
       " 'the gradients': 0.11438552290201187,\n",
       " 'these tools': 0.1164577454328537,\n",
       " 'program induction': 0.11840592324733734,\n",
       " 'regressions': 0.12013635039329529,\n",
       " 'atoms': 0.12039191275835037,\n",
       " 'max': 0.12146604061126709,\n",
       " 'retraining': 0.12289994955062866,\n",
       " 'loss minimization': 0.12317338585853577,\n",
       " 'test points': 0.125174418091774,\n",
       " 'regularization': 0.1256779432296753,\n",
       " 'its efficiency': 0.12772685289382935,\n",
       " 'proliferation': 0.1277674287557602,\n",
       " 'interference': 0.12864093482494354,\n",
       " 'months': 0.12947292625904083,\n",
       " 'the cold start problem': 0.12996631860733032,\n",
       " 'highlights': 0.1312865912914276,\n",
       " 'trends': 0.13151893019676208,\n",
       " 'visualization': 0.13161005079746246,\n",
       " 'exponential families': 0.13177244365215302,\n",
       " 'their combinations': 0.13184121251106262,\n",
       " 'infty': 0.13351547718048096,\n",
       " 'high dimensional state spaces': 0.13451506197452545,\n",
       " 'the ways': 0.1356460452079773,\n",
       " 'paintings': 0.1361493170261383,\n",
       " 'training error': 0.1376400589942932,\n",
       " 'decision making problems': 0.1388120949268341,\n",
       " 'payoffs': 0.13891157507896423,\n",
       " 'cross entropy loss': 0.13923554122447968,\n",
       " 'the documents': 0.13950517773628235,\n",
       " 'evolutionary deep intelligence': 0.14061743021011353,\n",
       " 'some extent': 0.140636146068573,\n",
       " 'optimizations': 0.1408657282590866,\n",
       " 'clustering problems': 0.1419670134782791,\n",
       " 'missing facts': 0.1432604044675827,\n",
       " 'weak labels': 0.14368923008441925,\n",
       " 'dueling bandits': 0.14465263485908508,\n",
       " 'the spectrum': 0.14601245522499084,\n",
       " 'the cost function': 0.14755654335021973,\n",
       " 'the domains': 0.14771917462348938,\n",
       " 'i': 0.15000177919864655,\n",
       " 'multiple labels': 0.15006382763385773,\n",
       " 'pairwise constraint propagation': 0.15088078379631042,\n",
       " 'probabilistic graphical models': 0.15108622610569,\n",
       " 'a trade': 0.151337668299675,\n",
       " '2': 0.1572689414024353,\n",
       " 'standards': 0.15981198847293854,\n",
       " 'disease': 0.16003450751304626,\n",
       " 'kernel methods': 0.16061758995056152,\n",
       " 'the heart': 0.16142764687538147,\n",
       " 'the use of deep neural networks': 0.16260521113872528,\n",
       " 'optimization problem': 0.1626819521188736,\n",
       " 'other approaches': 0.1627909243106842,\n",
       " 'load': 0.16509833931922913,\n",
       " 'object pose': 0.16768567264080048,\n",
       " 'convex functions': 0.1686515063047409,\n",
       " 'non markovian': 0.168653205037117,\n",
       " 'successes': 0.16880470514297485,\n",
       " 'the classification accuracy': 0.16950950026512146,\n",
       " 'probabilistic programs': 0.16965554654598236,\n",
       " 'limited precision': 0.1700391322374344,\n",
       " 'brl': 0.17014934122562408,\n",
       " 'the factors': 0.17055676877498627,\n",
       " 'summarization tasks': 0.1714157909154892,\n",
       " 'consumers': 0.17174716293811798,\n",
       " 'growing body': 0.1728978306055069,\n",
       " 'real world domains': 0.17345887422561646,\n",
       " 'a module': 0.1763496845960617,\n",
       " 'linear convergence': 0.17671334743499756,\n",
       " 'the latent variables': 0.17845582962036133,\n",
       " 'sample mean': 0.17940202355384827,\n",
       " 'tremendous success': 0.17992427945137024,\n",
       " 'the proofs': 0.18053407967090607,\n",
       " 'predictive performance': 0.18068300187587738,\n",
       " 'high quality images': 0.18265722692012787,\n",
       " 'workers': 0.18313883244991302,\n",
       " 'the necessity': 0.1834474354982376,\n",
       " 'biomedical literature': 0.1842154860496521,\n",
       " 'the limitation': 0.18761172890663147,\n",
       " 'statistical relational learning': 0.18787656724452972,\n",
       " 'itself': 0.189143106341362,\n",
       " 'the attention mechanism': 0.1918710172176361,\n",
       " 'coding schemes': 0.19463017582893372,\n",
       " 'both modalities': 0.19555844366550446,\n",
       " 'rotation': 0.19673220813274384,\n",
       " 'initial conditions': 0.19713237881660461,\n",
       " 'replacement': 0.1977422684431076,\n",
       " 'smile': 0.19980037212371826,\n",
       " 'this chapter': 0.20085585117340088,\n",
       " 'perception tasks': 0.20274053514003754,\n",
       " 'we': 0.20358113944530487,\n",
       " 'semantic relatedness': 0.20377574861049652,\n",
       " 'nlp systems': 0.20457151532173157,\n",
       " 'occurrence': 0.20654897391796112,\n",
       " 'investigation': 0.20990365743637085,\n",
       " 'society': 0.2110595703125,\n",
       " 'ground truth data': 0.21563811600208282,\n",
       " 'two challenges': 0.21680238842964172,\n",
       " 'item': 0.21698911488056183,\n",
       " 'reserve': 0.21982163190841675,\n",
       " 'execution': 0.22183121740818024,\n",
       " 'eda': 0.2238769382238388,\n",
       " 'sum': 0.22621551156044006,\n",
       " 'eyes': 0.22690588235855103,\n",
       " 'human supervision': 0.2273629754781723,\n",
       " 'the extent': 0.2349025309085846,\n",
       " 'other tasks': 0.2395196408033371,\n",
       " 'a resource': 0.23993787169456482,\n",
       " 'the energy landscape': 0.2401587814092636,\n",
       " 'entropy regularization': 0.24018807709217072,\n",
       " 'learning parameters': 0.24179662764072418,\n",
       " 'thanks': 0.24373428523540497,\n",
       " 'feed forward neural networks': 0.24774155020713806,\n",
       " 'multiple': 0.24864447116851807,\n",
       " 'websites': 0.24886339902877808,\n",
       " 'behavior': 0.25220900774002075,\n",
       " 'human concepts': 0.2554720342159271,\n",
       " 'hidden layer': 0.25632360577583313,\n",
       " 'the discriminator': 0.25715771317481995,\n",
       " 'epilepsy': 0.25735852122306824,\n",
       " 'transparency': 0.2588498592376709,\n",
       " 'counts': 0.25952059030532837,\n",
       " 'short term memory': 0.2623555362224579,\n",
       " 'a crucial step': 0.2640877068042755,\n",
       " 'renewed interest': 0.26536989212036133,\n",
       " 'novelty detection': 0.2659594416618347,\n",
       " 'its popularity': 0.26737695932388306,\n",
       " 'conditional random fields': 0.26927536725997925,\n",
       " 'noise ratio': 0.27147674560546875,\n",
       " 'kullback leibler kl': 0.2722280025482178,\n",
       " 'major issues': 0.2728152871131897,\n",
       " 'various constraints': 0.27339649200439453,\n",
       " 'robust optimization': 0.27944865822792053,\n",
       " 'scalability': 0.28425776958465576,\n",
       " 'frac 1 epsilon': 0.28515464067459106,\n",
       " 'risk prediction': 0.2921384274959564,\n",
       " 'ensemble methods': 0.2926195561885834,\n",
       " 'consensus clustering': 0.29393911361694336,\n",
       " 'lstms and grus': 0.2946302890777588,\n",
       " 'hyperparameters': 0.2984827756881714,\n",
       " 'chain graphs': 0.2999950647354126,\n",
       " 'geometric properties': 0.3020603656768799,\n",
       " 'negative samples': 0.305168092250824,\n",
       " 'out': 0.3052511513233185,\n",
       " 'the union': 0.3062560558319092,\n",
       " 'the fly': 0.3095199465751648,\n",
       " 'model learning': 0.3165648579597473,\n",
       " 'planes': 0.3187461197376251,\n",
       " 'theta': 0.31924164295196533,\n",
       " 'new approaches': 0.31958499550819397,\n",
       " 'information extraction': 0.3300864100456238,\n",
       " 'the sample size': 0.33700472116470337,\n",
       " 'a good model': 0.34214523434638977,\n",
       " 'interventions': 0.34915557503700256,\n",
       " 'a large number of classes': 0.35192203521728516,\n",
       " 'economics': 0.3532085418701172,\n",
       " 'ucf 101': 0.35428586602211,\n",
       " 'svi': 0.3570922315120697,\n",
       " 'activation function': 0.36236634850502014,\n",
       " 'bioner': 0.3626669943332672,\n",
       " 'perceptual tasks': 0.36594051122665405,\n",
       " 'atp': 0.3676706552505493,\n",
       " 'indexing': 0.3698779344558716,\n",
       " 'front': 0.37787580490112305,\n",
       " 'real time applications': 0.38927653431892395,\n",
       " 'rejection': 0.38979071378707886,\n",
       " 'the location': 0.3951883316040039,\n",
       " 'cue': 0.39854541420936584,\n",
       " 'analytics': 0.39897289872169495,\n",
       " 'deeper networks': 0.4012526869773865,\n",
       " 'purposes': 0.4030334949493408,\n",
       " 'computed tomography ct': 0.4066031277179718,\n",
       " 'rationality': 0.4132860004901886,\n",
       " 'learning ssl': 0.41574352979660034,\n",
       " 'sensors': 0.41575002670288086,\n",
       " 'experimental data': 0.4186810553073883,\n",
       " 'an empirical comparison': 0.4186990559101105,\n",
       " 'harness': 0.4227403700351715,\n",
       " 'crowdsourcing': 0.42541489005088806,\n",
       " 'the number': 0.42928555607795715,\n",
       " 'a new family': 0.44587719440460205,\n",
       " 'decision forests': 0.449590802192688,\n",
       " 'large scale machine learning': 0.44975513219833374,\n",
       " 'transactions': 0.44990670680999756,\n",
       " 'validation': 0.4547904431819916,\n",
       " 'handwriting': 0.4564620852470398,\n",
       " 'k nnc': 0.45814773440361023,\n",
       " 'strong theoretical guarantees': 0.46098729968070984,\n",
       " 'its applications': 0.4616880714893341,\n",
       " 'context': 0.46374431252479553,\n",
       " 'inclusion': 0.4649013876914978,\n",
       " 'procedure': 0.4649273455142975,\n",
       " 'clinical practice': 0.47165507078170776,\n",
       " 'surveillance': 0.47235792875289917,\n",
       " 'deformations': 0.4758360981941223,\n",
       " 'covariate': 0.47610288858413696,\n",
       " 'the aim': 0.47971174120903015,\n",
       " 'its impact': 0.4807462692260742,\n",
       " 'approximation algorithms': 0.48350000381469727,\n",
       " 'the sake': 0.48406800627708435,\n",
       " 'the input space': 0.48778462409973145,\n",
       " '2001': 0.48822957277297974,\n",
       " 'a general framework': 0.49040666222572327,\n",
       " 'attention mechanisms': 0.49127039313316345,\n",
       " 'knowledge graphs': 0.4939940571784973,\n",
       " 'td lambda': 0.497183233499527}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "better-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(extracted, open(f'data/pem_extracted_vs_{VECTOR_SIZE}_ws_{WINDOW_SIZE}_nl_{NUM_LAYERS}_mf_{MIN_FREQUENCY}_e_{EPOCHS}_t_{int(time.time())}.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pem",
   "language": "python",
   "name": "pem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
